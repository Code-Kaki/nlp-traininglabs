{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd762176",
   "metadata": {},
   "source": [
    "![license_header_logo](../../../images/license_header_logo.png)\n",
    "\n",
    "> **Copyright (c) 2021 CertifAI Sdn. Bhd.**<br>\n",
    "<br>\n",
    "This program is part of OSRFramework. You can redistribute it and/or modify\n",
    "<br>it under the terms of the GNU Affero General Public License as published by\n",
    "<br>the Free Software Foundation, either version 3 of the License, or\n",
    "<br>(at your option) any later version.\n",
    "<br>\n",
    "<br>This program is distributed in the hope that it will be useful\n",
    "<br>but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "<br>MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "<br>GNU Affero General Public License for more details.\n",
    "<br>\n",
    "<br>You should have received a copy of the GNU Affero General Public License\n",
    "<br>along with this program.  If not, see <http://www.gnu.org/licenses/>.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9101df86",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This handson is to demonstrate how to implement the tools, transformers and models from the HuggingFace library to create our own Machine Translation Model.\n",
    "\n",
    "Link to the HuggingFace Library: https://huggingface.co/models?sort=downloads\n",
    "\n",
    "You may check out slides Day 12 - Pretrained Model for NLP & Generalized Language Model, to get a detailed explanation and walkthrough on this handson.\n",
    "\n",
    "The walkthrough includes:\n",
    "\n",
    "1. Explaination of code\n",
    "2. How to find the model we want from HuggingFace and implement them into the code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddeeede",
   "metadata": {},
   "source": [
    "# What we will accomplish?\n",
    "\n",
    "1. Use transformers in HuggingFace\n",
    "2. Import the correct model from HuggingFace\n",
    "3. Create your own Machine Translation model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad641653",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "Read the code and execute them according to the instructions provided. If you are having trouble understanding the code, you may take a look at slides, Day 12 - Pretrained Model for NLP & Generalized Language Model, Machine Translation Handson to get a better understanding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfe5c07",
   "metadata": {},
   "source": [
    "# Part 1: Code and its explanation\n",
    "\n",
    "First, we will install the required libraries.\n",
    "torch refers to PyTorch library and transformers refers to the HuggingFace transformers library.\n",
    "We need to install PyTorch in order to utilize the HuggingFace models and transformers.\n",
    "If you already have installed, you can skip this step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8b44ce",
   "metadata": {},
   "source": [
    "AutoModelForSeq2SeqLM is where machine translation models fall under in the HuggingFace library.\n",
    "AutoTokenizer is where we can define tokenizers from the HuggingFace library.\n",
    "Pipeline is a method where we can automate the workflow to produce machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c027c1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8755209f",
   "metadata": {},
   "source": [
    "model is where we will be defining the machine translation model\n",
    "we are importing a pretrained model (indicated by from_pretraied) that is the Helsinki model\n",
    "\n",
    "tokenizer is where we define tokenizer, also this is a tokenizer from pretrained Helsinki model\n",
    "\n",
    "translation is where we call the pipeline method to automate the machine translation workflow\n",
    "here we defined what process it is going to in the parameters\n",
    "first parameter, “translation_mul_to_en” means translation of multi language to english\n",
    "second parameter, model=model is just us inserting the model we already initialized above\n",
    "third parameter, tokenizer=tokenizer is also just us inserting the tokenizer already initialized above "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9014862c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"Helsinki-NLP/opus-mt-mul-en\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-mul-en\")\n",
    "\n",
    "translation = pipeline(\"translation\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e02ac6",
   "metadata": {},
   "source": [
    "text is obviously the text that we want to translate\n",
    "\n",
    "translated_text is where we define translated text (Malay to English translated text)\n",
    "the translation method will translate the text to English\n",
    "this method will return a dict, so we want to print only the content of the first element[0] in the dict tagged with ‘translation_text’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f477bec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My name is Michael. What's your name?\n"
     ]
    }
   ],
   "source": [
    "text = \"Nama saya Micheal, siapakah nama awak?\"\n",
    "translated_text = translation(text)[0]['translation_text']\n",
    "\n",
    "print(translated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad48ff8",
   "metadata": {},
   "source": [
    "# Part 2: Choosing the proper model from HuggingFace\n",
    "\n",
    "In this task, you are required to go to the hugging face website to look for the model that can translate english to chinese.\n",
    "HuggingFace website: https://huggingface.co/models?sort=downloads\n",
    "\n",
    "If you are having trouble with this task, take a look at slides Day 12 - Pretrained Model for NLP & Generalized Language Model, to get a detailed explanation and walkthrough on this handson.\n",
    "\n",
    "You will have to find the appropriate model, copy the name of the model provided and paste it into the model and tokenizer parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "817a26ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, pipeline\n",
    "\n",
    "# model = AutoModelForSeq2SeqLM.from_pretrained(\"COPY AND PASTE THE MODEL NAME HERE\")\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"COPY AND PASTE THE MODEL NAME HERE\")\n",
    "\n",
    "# translation = pipeline(\"translation\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "# text = \"Hi, how are you?\"\n",
    "# translated_text = translation(text)[0]['translation_text']\n",
    "\n",
    "# print(translated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b5943c",
   "metadata": {},
   "source": [
    "# Summary\n",
    "Now you know how to create your own machine translation using HuggingFace Library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64b4df3",
   "metadata": {},
   "source": [
    "# Contributors\n",
    "Author\n",
    "Pahvindran Raj"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
