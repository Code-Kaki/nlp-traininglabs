{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c730b369",
   "metadata": {},
   "source": [
    "![license_header_logo](../../../images/license_header_logo.png)\n",
    "\n",
    "> **Copyright (c) 2021 CertifAI Sdn. Bhd.**<br>\n",
    "<br>\n",
    "This program is part of OSRFramework. You can redistribute it and/or modify\n",
    "<br>it under the terms of the GNU Affero General Public License as published by\n",
    "<br>the Free Software Foundation, either version 3 of the License, or\n",
    "<br>(at your option) any later version.\n",
    "<br>\n",
    "<br>This program is distributed in the hope that it will be useful\n",
    "<br>but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "<br>MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "<br>GNU Affero General Public License for more details.\n",
    "<br>\n",
    "<br>You should have received a copy of the GNU Affero General Public License\n",
    "<br>along with this program.  If not, see <http://www.gnu.org/licenses/>.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c73a60f",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "**Word embeddings** are a modern approach for **representing text** in natural language processing.\n",
    "\n",
    "[Word embedding](https://machinelearningmastery.com/what-are-word-embeddings/) algorithms like **word2vec**, **doc2vec** and **GloVe** are key to the state-of-the-art results achieved by neural network models on natural language processing problems like machine translation.\n",
    "\n",
    "In this notebook, you will discover how to **train and load word embedding models** for natural language processing applications in Python using **Gensim**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bdf409",
   "metadata": {},
   "source": [
    "# What will we accomplish?\n",
    "\n",
    "By the end of this tutorial, you will know:\n",
    "\n",
    "1. How to train your own word2vec word embedding model on text data.\n",
    "\n",
    "\n",
    "2. How to visualize a trained word embedding model using Principal Component Analysis.\n",
    "\n",
    "\n",
    "3. How to train simple doc2vec embeddings using Gensim\n",
    "\n",
    "\n",
    "4. How to load pre-trained word2vec and GloVe word embedding models from Google and Stanford."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327ff254",
   "metadata": {},
   "source": [
    "# Notebook Content\n",
    "\n",
    "* [Introduction to Word Embeddings](#Introduction-to-Word-Embeddings)\n",
    "\n",
    "\n",
    "* [Gensim Library](#Gensim-Python-Library)\n",
    "\n",
    "\n",
    "* [Develop Word2Vec Embedding](#Develop-Word2Vec-Embedding)\n",
    "\n",
    "\n",
    "* [Visualize Word Embedding](#Visualize-Word-Embedding)\n",
    "\n",
    "\n",
    "* [Load Google’s Word2Vec Embedding](#Load-Google’s-Word2Vec-Embedding)\n",
    "\n",
    "\n",
    "* [Load Stanford’s GloVe Embedding](#Load-Stanford’s-GloVe-Embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a51012d",
   "metadata": {},
   "source": [
    "# Introduction to Word Embeddings\n",
    "\n",
    "A **word embedding** is an approach to provide a **dense vector representation** of words that capture something about their meaning.\n",
    "\n",
    "Word embeddings are an improvement over simpler bag-of-word model word encoding schemes like word counts and frequencies that result in large and sparse vectors (mostly 0 values) that describe documents but not the meaning of the words.\n",
    "\n",
    "Word embeddings work by using an algorithm to train a set of **fixed-length dense and continuous-valued vectors** based on a large corpus of text. Each word is represented by a point in the embedding space and these points are learned and moved around based on the words that surround the target word.\n",
    "\n",
    "It is defining a word by the company that it keeps that allows the word embedding to learn something about the **meaning of words**. The vector space representation of the words provides a projection where words with similar meanings are locally clustered within the space.\n",
    "\n",
    "The use of word embeddings over other text representations is one of the key methods that has led to breakthrough performance with deep neural networks on problems like machine translation.\n",
    "\n",
    "In this tutorial, we are going to look at how to implement **word2vec** and **doc2vec** algorithm using Gensim as well as use two different pretrained word embedding methods called **word2vec** by researchers at Google and **GloVe** by researchers at Stanford."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c50b1c7",
   "metadata": {},
   "source": [
    "# Gensim Python Library\n",
    "\n",
    "[Gensim](https://radimrehurek.com/gensim/index.html) is an open source Python library for natural language processing, with a focus on topic modeling. It was developed and is maintained by the Czech natural language processing researcher Radim Řehůřek and his company RaRe Technologies.\n",
    "\n",
    "<img src=\"../../../images/gensim.png\" width=\"400\" height=\"500\"/>\n",
    "     \n",
    "It is not an everything-including-the-kitchen-sink NLP research library (like NLTK); instead, Gensim is a mature, focused, and efficient suite of NLP tools for **topic modeling**. Most notably for this tutorial, it supports an implementation of the Word2Vec and Doc2Vec embedding for learning new word vectors from text.\n",
    "\n",
    "It also provides tools for loading **pre-trained word embeddings** in a few formats and for making use and querying a loaded embedding.\n",
    "\n",
    "Now, we will use Gensim for word embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea47342d",
   "metadata": {},
   "source": [
    "# Develop Word2Vec Embedding\n",
    "\n",
    "Word2vec is one algorithm for learning a word embedding from a text corpus.\n",
    "\n",
    "There are two main training algorithms that can be used to learn the embedding from text; they are **continuous bag of words (CBOW)** and **skip grams**.\n",
    "\n",
    "We will not get into the algorithms other than to say that they generally look at a **window of words** for each target word to provide context and in turn meaning for words. The approach was developed by Tomas Mikolov, formerly at Google and currently at Facebook.\n",
    "\n",
    "Word2Vec models require a lot of text, e.g. the entire Wikipedia corpus. Nevertheless, we will demonstrate the principles using a small in-memory example of text.\n",
    "\n",
    "Gensim provides the `Word2Vec` class for working with a Word2Vec model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f74db93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Word2Vec model\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd3a674",
   "metadata": {},
   "source": [
    "Specifically, each sentence must be **tokenized**, meaning divided into words and prepared (e.g. perhaps pre-filtered and perhaps converted to a preferred case).\n",
    "\n",
    "The sentences could be text loaded into memory, or an iterator that progressively loads text, required for very large text corpora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afca0c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training data\n",
    "sentences = [['this', 'is', 'the', 'first', 'sentence', 'for', 'word2vec'],\n",
    "            ['this', 'is', 'the', 'second', 'sentence'],\n",
    "            ['yet', 'another', 'sentence'],\n",
    "            ['one', 'more', 'sentence'],\n",
    "            ['and', 'the', 'final', 'sentence']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cbde38",
   "metadata": {},
   "source": [
    "There are many parameters on `Word2Vec` constructor; a few noteworthy arguments you may wish to configure are:\n",
    "\n",
    "* **size**: (default 100) The number of **dimensions** of the embedding,\n",
    "  </br>e.g. the length of the **dense vector** to represent each token (word).\n",
    "  \n",
    "  \n",
    "* **window**: (default 5) The maximum distance between a target word and words around the target word.\n",
    "\n",
    "\n",
    "* **min_count**: (default 5) The minimum count of words to consider when training the model; words with an occurrence less than this count will be ignored.\n",
    "\n",
    "\n",
    "* **workers**: (default 3) The number of threads to use while training.\n",
    "\n",
    "\n",
    "* **sg**: (default 0 or CBOW) The training algorithm, either CBOW (0) or skip gram (1).\n",
    "\n",
    "\n",
    "The defaults are often good enough when just getting started. If you have a lot of cores, as most modern computers do, I strongly encourage you to increase workers to match the number of cores (e.g. 8)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "409acb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "model = Word2Vec(sentences, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79a1db27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=14, vector_size=100, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "# Summarize the loaded model\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c980e8",
   "metadata": {},
   "source": [
    "After the model is trained, it is accessible via the **`wv`** attribute. This is the actual **word vector model** in which queries can be made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e018bf7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sentence', 'the', 'is', 'this', 'final', 'and', 'more', 'one', 'another', 'yet', 'second', 'word2vec', 'for', 'first']\n"
     ]
    }
   ],
   "source": [
    "# Print the learned vocabulary of tokens (words)\n",
    "words = list(model.wv.key_to_index)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5f721b",
   "metadata": {},
   "source": [
    "You also can review the **embedded vector** for a specific token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cd335a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-5.3622725e-04  2.3643016e-04  5.1033497e-03  9.0092728e-03\n",
      " -9.3029495e-03 -7.1168090e-03  6.4588715e-03  8.9729885e-03\n",
      " -5.0154282e-03 -3.7633730e-03  7.3805046e-03 -1.5334726e-03\n",
      " -4.5366143e-03  6.5540504e-03 -4.8601604e-03 -1.8160177e-03\n",
      "  2.8765798e-03  9.9187379e-04 -8.2852151e-03 -9.4488189e-03\n",
      "  7.3117660e-03  5.0702621e-03  6.7576934e-03  7.6286553e-04\n",
      "  6.3508893e-03 -3.4053659e-03 -9.4640255e-04  5.7685734e-03\n",
      " -7.5216386e-03 -3.9361049e-03 -7.5115822e-03 -9.3004224e-04\n",
      "  9.5381187e-03 -7.3191668e-03 -2.3337698e-03 -1.9377422e-03\n",
      "  8.0774352e-03 -5.9308959e-03  4.5161247e-05 -4.7537349e-03\n",
      " -9.6035507e-03  5.0072931e-03 -8.7595871e-03 -4.3918253e-03\n",
      " -3.5099984e-05 -2.9618264e-04 -7.6612402e-03  9.6147414e-03\n",
      "  4.9820566e-03  9.2331432e-03 -8.1579182e-03  4.4957972e-03\n",
      " -4.1370774e-03  8.2453492e-04  8.4986184e-03 -4.4621779e-03\n",
      "  4.5175003e-03 -6.7869616e-03 -3.5484887e-03  9.3985079e-03\n",
      " -1.5776539e-03  3.2137157e-04 -4.1406299e-03 -7.6826881e-03\n",
      " -1.5080094e-03  2.4697948e-03 -8.8802812e-04  5.5336617e-03\n",
      " -2.7429771e-03  2.2600652e-03  5.4557943e-03  8.3459523e-03\n",
      " -1.4537406e-03 -9.2081428e-03  4.3705511e-03  5.7178497e-04\n",
      "  7.4419067e-03 -8.1328390e-04 -2.6384138e-03 -8.7530091e-03\n",
      " -8.5655687e-04  2.8265619e-03  5.4014279e-03  7.0526553e-03\n",
      " -5.7031228e-03  1.8588186e-03  6.0888622e-03 -4.7980524e-03\n",
      " -3.1072616e-03  6.7976285e-03  1.6314745e-03  1.8991709e-04\n",
      "  3.4736372e-03  2.1777629e-04  9.6188262e-03  5.0606038e-03\n",
      " -8.9173913e-03 -7.0415614e-03  9.0145587e-04  6.3925339e-03]\n"
     ]
    }
   ],
   "source": [
    "# Access vector for one word\n",
    "print(model.wv['sentence'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616c161a",
   "metadata": {},
   "source": [
    "Finally, a trained model can then be **saved to file** by calling the `save()` function on the **Word2Vec model**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6db0662d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model.save('model/word2vec.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9dcde4",
   "metadata": {},
   "source": [
    "When getting started, you can save the learned model in **ASCII format** and review the contents.\n",
    "\n",
    "You can do this by setting `binary=False` when calling the `save_word2vec_format()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b0c4c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model as text\n",
    "model.wv.save_word2vec_format('model/word2vec.txt', binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0f8324",
   "metadata": {},
   "source": [
    "The saved model can then be **loaded** again by calling the `Word2Vec.load()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd88fd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "loaded_model = Word2Vec.load('model/word2vec.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6091614",
   "metadata": {},
   "source": [
    "You can see that with a little work to prepare your text document, you can create your own word embedding very easily with Gensim."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3289624",
   "metadata": {},
   "source": [
    "# Visualize Word Embedding\n",
    "\n",
    "After you learn word embedding for your text data, it can be nice to explore it with **visualization**.\n",
    "\n",
    "You can use classical projection methods to reduce the high-dimensional word vectors to two-dimensional plots and plot them on a graph.\n",
    "\n",
    "The visualizations can provide a qualitative diagnostic for your learned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5eb2212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-5.3622725e-04  2.3643016e-04  5.1033497e-03 ... -7.0415614e-03\n",
      "   9.0145587e-04  6.3925339e-03]\n",
      " [-8.6196875e-03  3.6657380e-03  5.1898835e-03 ... -2.3915148e-03\n",
      "  -9.5100952e-03  4.5058774e-03]\n",
      " [ 9.4563962e-05  3.0773187e-03 -6.8126465e-03 ...  5.1259040e-04\n",
      "   8.2130842e-03 -7.0190406e-03]\n",
      " ...\n",
      " [ 9.7702928e-03  8.1651136e-03  1.2809705e-03 ... -2.9727411e-03\n",
      "  -4.9318983e-03 -2.3151112e-03]\n",
      " [-1.9442177e-03 -5.2675223e-03  9.4471117e-03 ...  5.9827138e-03\n",
      "   6.8153618e-03  7.8225443e-03]\n",
      " [-9.5001198e-03  9.5622232e-03 -7.7707553e-03 ... -3.1351089e-03\n",
      "  -6.3388203e-03  9.8700766e-03]]\n"
     ]
    }
   ],
   "source": [
    "# Retrieve all of the vectors from a trained model\n",
    "\n",
    "X = model.wv[model.wv.key_to_index]\n",
    "\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e5461a",
   "metadata": {},
   "source": [
    "We can then train a projection method on the vectors from those methods offered in **scikit-learn**, then use **matplotlib** to plot the projection as a scatter plot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3540e07",
   "metadata": {},
   "source": [
    "## Plot Word Vectors Using PCA\n",
    "\n",
    "We can create a **2-dimensional PCA model** of the word vectors using the scikit-learn `PCA` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4228726e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import PCA from sklearn\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23b81546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a 2d PCA model to the vectors\n",
    "pca = PCA(n_components=2)\n",
    "result = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d634e56f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f374a9",
   "metadata": {},
   "source": [
    "The resulting projection can be plotted using **matplotlib** as follows, pulling out the two dimensions as **x** and **y** coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "292e3e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pyplot as plt\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4748173",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a scatter plot of the projection\n",
    "plt.scatter(result[:, 0], result[:, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175235cc",
   "metadata": {},
   "source": [
    "We can go one step further and **annotate the points** on the graph with the words themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dda8dca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "words = list(model.wv.key_to_index)\n",
    "\n",
    "plt.scatter(result[:, 0], result[:, 1])\n",
    "for i, word in enumerate(words):\n",
    "    plt.annotate(word, xy=(result[i, 0], result[i, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "349e709c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e408c9",
   "metadata": {},
   "source": [
    "**Note**: Your results may vary given the **stochastic nature** of the algorithm or evaluation procedure, or differences in numerical precision. Consider running the example a few times and compare the average outcome.\n",
    "\n",
    "It is hard to pull much meaning out of the graph given such a **tiny corpus** was used to fit the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093078ea",
   "metadata": {},
   "source": [
    "# Develop Doc2Vec Embedding\n",
    "\n",
    "Doc2vec (also known as: paragraph2vec or sentence embedding) is the modified version of word2vec. The main objective of doc2vec is to **convert sentence or paragraph to vector (numeric) form**. In Natural Language Processing, Doc2Vec is used to find related sentences for a given sentence.\n",
    "\n",
    "![Doc2Vec](../../../images/doc2vec.png)\n",
    "\n",
    "In this section, we are going to code a  **simple implementation of doc2vec** using Python and Gensim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20267e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exapmple document (list of sentences)\n",
    "doc = [\"I love data science\",\n",
    "        \"I love coding in python\",\n",
    "        \"I love building NLP tool\",\n",
    "        \"This is a good phone\",\n",
    "        \"This is a good TV\",\n",
    "        \"This is a good laptop\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48c8f56",
   "metadata": {},
   "source": [
    "As in word2vec implementation, we need to tokenize each sentence into words. Here we are going to use `word_tokenize` function from `nltk` library to tokenize each sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d8e54377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import word_tokenize function\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f6b5666",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['i', 'love', 'data', 'science'],\n",
       " ['i', 'love', 'coding', 'in', 'python'],\n",
       " ['i', 'love', 'building', 'nlp', 'tool'],\n",
       " ['this', 'is', 'a', 'good', 'phone'],\n",
       " ['this', 'is', 'a', 'good', 'tv'],\n",
       " ['this', 'is', 'a', 'good', 'laptop']]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start tokenization\n",
    "tokenized_doc = []\n",
    "for d in doc:\n",
    "    tokenized_doc.append(word_tokenize(d.lower()))\n",
    "    \n",
    "tokenized_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68ec01e",
   "metadata": {},
   "source": [
    "![Doc2Vec Implementation](../../../images/doc2vec_implementation.gif)\n",
    "\n",
    "From the figure above, we can observe that there is a `document_id` inserted into the vector. This is the key implementation of Doc2Vec and here we using `TaggedDocument` function to assign tag (id) to each documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bcc65d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import TaggedDocument function\n",
    "from gensim.models.doc2vec import TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d08519cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TaggedDocument(words=['i', 'love', 'data', 'science'], tags=[0]),\n",
       " TaggedDocument(words=['i', 'love', 'coding', 'in', 'python'], tags=[1]),\n",
       " TaggedDocument(words=['i', 'love', 'building', 'nlp', 'tool'], tags=[2]),\n",
       " TaggedDocument(words=['this', 'is', 'a', 'good', 'phone'], tags=[3]),\n",
       " TaggedDocument(words=['this', 'is', 'a', 'good', 'tv'], tags=[4]),\n",
       " TaggedDocument(words=['this', 'is', 'a', 'good', 'laptop'], tags=[5])]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert tokenized document into gensim formated tagged data\n",
    "tagged_data = [TaggedDocument(d, [i]) for i, d in enumerate(tokenized_doc)]\n",
    "\n",
    "tagged_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27086c9",
   "metadata": {},
   "source": [
    "Now we are ready to train our doc2vec model.\n",
    "\n",
    "In this tutorial, we are using **distributed memory paragraph vector (PV-DM)** model as doc2vec.\n",
    "\n",
    "**Note**: `dm=1` **means distributed memory (PV-DM)** and `dm=0` means **distributed bag of words (PV-DBOW)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "52407bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Doc2Vec model\n",
    "from gensim.models.doc2vec import Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "70ebf9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Doc2Vec model\n",
    "model = Doc2Vec(tagged_data, vector_size=20, window=2, min_count=1, workers=4, epochs = 100, dm=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b14113b",
   "metadata": {},
   "source": [
    "You can access the vocabulary list in the doc2vec using `wv` attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "23e4428b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'love',\n",
       " 'good',\n",
       " 'a',\n",
       " 'is',\n",
       " 'this',\n",
       " 'in',\n",
       " 'data',\n",
       " 'science',\n",
       " 'coding',\n",
       " 'laptop',\n",
       " 'python',\n",
       " 'building',\n",
       " 'tv',\n",
       " 'tool',\n",
       " 'phone',\n",
       " 'nlp']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.wv.key_to_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3185ad3e",
   "metadata": {},
   "source": [
    "You also can easily find the most similar document using `model.docvecs.most_similar` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "98a450c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 0.31323811411857605), (4, 0.1339501142501831), (1, 0.04293661192059517)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find most similar doc \n",
    "test_doc = word_tokenize(\"That is a good device\".lower())\n",
    "\n",
    "model.dv.most_similar(positive=[model.infer_vector(test_doc)],topn=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295d0521",
   "metadata": {},
   "source": [
    "Similar to word2vec, a trained model can then be saved to file by calling the `save()` function on the Doc2Vec model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c58b8382",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"model/doc2vec.model\"\n",
    "model.save(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79e4617",
   "metadata": {},
   "source": [
    "The saved model can then be loaded again by calling the `Doc2Vec.load()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "606fcc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = Doc2Vec.load(\"model/doc2vec.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4954ce4f",
   "metadata": {},
   "source": [
    "# Load Google’s Word2Vec Embedding\n",
    "\n",
    "Training your own word vectors may be the best approach for a given NLP problem.\n",
    "\n",
    "But it can take a long time, a fast computer with **a lot of RAM and disk space**, and perhaps some expertise in finessing the input data and training algorithm.\n",
    "\n",
    "An alternative is to simply use an existing **pre-trained word embedding**.\n",
    "\n",
    "Along with the paper and code for word2vec, Google also published a pre-trained word2vec model on the [Word2Vec Google Code Project](https://code.google.com/archive/p/word2vec/).\n",
    "\n",
    "A pre-trained model is nothing more than a file containing **tokens** and their **associated word vectors**. The pre-trained Google word2vec model was trained on **Google news data (about 100 billion words)**; it contains 3 million words and phrases and was fit using **300-dimensional word vectors**.\n",
    "\n",
    "It is a 1.53 Gigabytes file. You can download it from here:\n",
    "\n",
    "* [GoogleNews-vectors-negative300.bin.gz](https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit?resourcekey=0-wjGZdNAUop6WykTtMip30g)\n",
    "\n",
    "Unzipped, the binary file (GoogleNews-vectors-negative300.bin) is 3.4 Gigabytes.\n",
    "\n",
    "**Note**: You should have \"GoogleNews-vectors-negative300.bin`dataset` folder, else you may download it from the link above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3c3ca5",
   "metadata": {},
   "source": [
    "Gensim library provides tools to load this file. Specifically, you can call the `KeyedVectors.load_word2vec_format()` function to load model into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ea36b252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import KeyedVectors\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b0255af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the google word2vec model\n",
    "filename = '../../../resources/day_07/GoogleNews-vectors-negative300.bin'\n",
    "model = KeyedVectors.load_word2vec_format(filename, binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe045603",
   "metadata": {},
   "source": [
    "Another interesting thing that you can do is do a little **linear algebra arithmetic** with words. For example, a popular example described in lectures and introduction papers is:\n",
    "\n",
    "> queen = (king - man) + woman\n",
    "\n",
    "That is the word queen is the closest word given the subtraction of the notion of man from king and adding the word woman. The “man-ness” in king is replaced with “woman-ness” to give us queen. A very cool concept.\n",
    "\n",
    "Gensim provides an interface for performing these types of operations in the `most_similar()` function on the trained or loaded model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e2f0ed95",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('queen', 0.7118193507194519)]\n"
     ]
    }
   ],
   "source": [
    "# Calculate: (king - man) + woman = ?\n",
    "result = model.most_similar(positive=['woman', 'king'], negative=['man'], topn=1)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df278d76",
   "metadata": {},
   "source": [
    "# Load Stanford’s GloVe Embedding\n",
    "\n",
    "Stanford researchers also have their own word embedding algorithm like word2vec called **[Global Vectors for Word Representation](https://nlp.stanford.edu/projects/glove/)**, or **GloVe** for short.\n",
    "\n",
    "We won’t get into the details of the differences between word2vec and GloVe here, but generally, NLP practitioners seem to prefer GloVe at the moment based on results.\n",
    "\n",
    "Like word2vec, the GloVe researchers also provide **pre-trained word vectors**, in this case, a great selection to choose from.\n",
    "\n",
    "You can download the smallest GloVe pre-trained model from the [GloVe](https://nlp.stanford.edu/projects/glove/) website and load them easily with gensim. It an **822 Megabyte zip** file with 4 different models (50, 100, 200 and 300-dimensional vectors) trained on **Wikipedia data** with 6 billion tokens and a **400,000 word vocabulary**.\n",
    "\n",
    "The direct download link is here:\n",
    "\n",
    "* [glove.6B.zip](http://nlp.stanford.edu/data/glove.6B.zip)\n",
    "\n",
    "The distinct different between GloVe text vector and word2vec bin files is the header. To read the GolVe text vector, we use `KeyedVectors.load_word2vec_format` function with parameters `binary=False` and `no_header=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6994ce26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import KeyedVectors\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c1b1b3",
   "metadata": {},
   "source": [
    "Now we can load GolVe text vector and perform the same `(king – man) + woman = ?` test as in the previous section. \n",
    "\n",
    "Note that the converted file is **ASCII format**, not binary, so we set `binary=False` when loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1b59be79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('queen', 0.7698541283607483)]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "# Load the Stanford GloVe model\n",
    "filename = '../../../resources/.vector_cache/glove.6B.100d.txt'\n",
    "model = KeyedVectors.load_word2vec_format(filename, binary=False, no_header=True)\n",
    "# calculate: (king - man) + woman = ?\n",
    "result = model.most_similar(positive=['woman', 'king'], negative=['man'], topn=1)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebb18f3",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "In this tutorial, you discovered how to develop and load word embedding layers in Python using **Gensim**.\n",
    "\n",
    "Specifically, you learned:\n",
    "\n",
    "* How to train your own word2vec and doc2vec word embedding model on text data.\n",
    "* How to visualize a trained word embedding model using Principal Component Analysis.\n",
    "* How to load pre-trained word2vec and GloVe word embedding models from Google and Stanford."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d901d3",
   "metadata": {},
   "source": [
    "# Contributors\n",
    "\n",
    "**Author**\n",
    "<br>Chee Lam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eca230d",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "1. [How to Develop Word Embeddings in Python with Gensim](https://machinelearningmastery.com/develop-word-embeddings-python-gensim/)\n",
    "\n",
    "2. [Gensim Doc2Vec Python implementation](https://thinkinfi.com/gensim-doc2vec-python-implementation/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
