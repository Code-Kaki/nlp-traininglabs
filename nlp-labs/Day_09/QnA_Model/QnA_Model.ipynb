{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49da9fa9",
   "metadata": {},
   "source": [
    "![license_header_logo](../../../images/license_header_logo.png)\n",
    "\n",
    "> **Copyright (c) 2021 CertifAI Sdn. Bhd.**<br>\n",
    "<br>\n",
    "This program is part of OSRFramework. You can redistribute it and/or modify\n",
    "<br>it under the terms of the GNU Affero General Public License as published by\n",
    "<br>the Free Software Foundation, either version 3 of the License, or\n",
    "<br>(at your option) any later version.\n",
    "<br>\n",
    "<br>This program is distributed in the hope that it will be useful\n",
    "<br>but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "<br>MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "<br>GNU Affero General Public License for more details.\n",
    "<br>\n",
    "<br>You should have received a copy of the GNU Affero General Public License\n",
    "<br>along with this program.  If not, see <http://www.gnu.org/licenses/>.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba5dd16",
   "metadata": {},
   "source": [
    "INSTRUCTION: Take a look at an example of a pretrained QnA model using PyTorch and HuggingFace Library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4149f3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ninstall torch(PyTorch) and transformers\\nto install them type in your terminal:\\npip install torch\\npip install transformers\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "install torch(PyTorch) and transformers\n",
    "to install them type in your terminal:\n",
    "pip install torch\n",
    "pip install transformers\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36054651",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-cased-distilled-squad (https://huggingface.co/distilbert-base-cased-distilled-squad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "821c629968224599875de909e6e542f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/473 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc61977330504c37baba53679795789b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/261M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "555addaade99485081c37f5dd8d5d6dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7db9a585adde47969229f4631bfcc62c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bf7b2d8db3440118edc0195ee7ee6db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: sample data\n",
      "Score: 0.8846666812896729\n"
     ]
    }
   ],
   "source": [
    "# import the necessary library\n",
    "from transformers import pipeline\n",
    "\n",
    "# define your context (where model seeks the answer for the question)\n",
    "context = \"\"\"\n",
    "Machine learning (ML) is the study of computer algorithms that improve automatically through experience. It is seen as a part of artificial intelligence. Machine learning algorithms build a model based on sample data, known as \"training data\", in order to make predictions or decisions without being explicitly programmed to do so. Machine learning algorithms are used in a wide variety of applications, such as email filtering and computer vision, where it is difficult or unfeasible to develop conventional algorithms to perform the needed tasks.\n",
    "\"\"\"\n",
    "\n",
    "# define your question\n",
    "question = \"What are machine learning models based on?\"\n",
    "\n",
    "# initialize your model\n",
    "\"\"\"\n",
    "This is a pretrained model that we can get from huggingface\n",
    "There are more models that we can find there: https://huggingface.co/\n",
    "\"\"\"\n",
    "question_answering = pipeline('question-answering')\n",
    "\n",
    "\n",
    "# test the model\n",
    "result = question_answering(question=question, context=context)\n",
    "print(\"Answer:\", result['answer'])\n",
    "print(\"Score:\", result['score'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
