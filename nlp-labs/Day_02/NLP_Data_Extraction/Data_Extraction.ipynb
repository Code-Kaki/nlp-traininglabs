{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c730b369",
   "metadata": {},
   "source": [
    "> **Copyright (c) 2020 Skymind Holdings Berhad**<br><br>\n",
    "> **Copyright (c) 2021 Skymind Education Group Sdn. Bhd.**<br>\n",
    "<br>\n",
    "Licensed under the Apache License, Version 2.0 (the \\\"License\\\");\n",
    "<br>you may not use this file except in compliance with the License.\n",
    "<br>You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0/\n",
    "<br>\n",
    "<br>Unless required by applicable law or agreed to in writing, software\n",
    "<br>distributed under the License is distributed on an \\\"AS IS\\\" BASIS,\n",
    "<br>WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "<br>See the License for the specific language governing permissions and\n",
    "<br>limitations under the License.\n",
    "<br>\n",
    "<br>\n",
    "**SPDX-License-Identifier: Apache-2.0**\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d407be03",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook is to introduce the basic of data extraction from various source. The first stage of NLP project is to extract the required textual data. The data is usually unstructured and is stored in a varying number of sources.\n",
    "This article illustrates how we can extract text based data from the most common sources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7286a59",
   "metadata": {},
   "source": [
    "# Notebook Content\n",
    "\n",
    "* [Extract Table From A Webpage](#Extract-Table-From-A-Webpage)\n",
    "\n",
    "\n",
    "* [Extract Tweets](#Extract-Tweets)\n",
    "\n",
    "\n",
    "* [Extract Text From A HTML Webpage](#Extract-Text-From-A-HTML-Webpage)\n",
    "\n",
    "\n",
    "* [Read A Word Document](#Read-A-Word-Document)\n",
    "\n",
    "\n",
    "* [Read A PDF Document](#Read-A-PDF-Document)\n",
    "\n",
    "\n",
    "* [Read Text From A Csv File](#Read-Text-From-A-Csv-File)\n",
    "\n",
    "\n",
    "* [Read Text From An Excel Spreadsheet](#Read-Text-From-An-Excel-Spreadsheet)\n",
    "\n",
    "\n",
    "* [Read Outlook Emails](#Read-Outlook-Emails)\n",
    "\n",
    "\n",
    "* [Extract RSS Feeds](#Extract-RSS-Feeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e771d2e",
   "metadata": {},
   "source": [
    "## Extract Table From A Webpage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3639d7e5",
   "metadata": {},
   "source": [
    "Often the facts and figures are represented in a table in a HTML webpage. If we want to extract a HTML table from a web page then we can use Pandas library. The method reads HTML tables into a `list` of `DataFrame` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fcb4225",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e3816d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass in the url to extract the tables\n",
    "url = \"https://en.wikipedia.org/wiki/Artificial_intelligence\"\n",
    "table_lists = pd.read_html(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b8cd25e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[                                                   0\n",
       " 0                                Part of a series on\n",
       " 1                            Artificial intelligence\n",
       " 2  Major goals Artificial general intelligence Pl...\n",
       " 3  Approaches Symbolic Deep learning Bayesian net...\n",
       " 4  Philosophy Ethics Existential risk Turing test...\n",
       " 5                History Timeline Progress AI winter\n",
       " 6  Technology Applications Projects Programming l...\n",
       " 7                                  Glossary Glossary\n",
       " 8  .mw-parser-output .navbar{display:inline;font-...,\n",
       "                                                     0\n",
       " 0                                 Part of a series on\n",
       " 1                     Machine learningand data mining\n",
       " 2   Problems Classification Clustering Regression ...\n",
       " 3   Supervised learning.mw-parser-output .nobold{f...\n",
       " 4   Clustering BIRCH CURE Hierarchical k-means Exp...\n",
       " 5   Dimensionality reduction Factor analysis CCA I...\n",
       " 6   Structured prediction Graphical models Bayes n...\n",
       " 7         Anomaly detection k-NN Local outlier factor\n",
       " 8   Artificial neural network Autoencoder Cognitiv...\n",
       " 9   Reinforcement learning Q-learning SARSA Tempor...\n",
       " 10  Theory Bias–variance tradeoff Computational le...\n",
       " 11  Machine-learning venues NeurIPS ICML ML JMLR A...\n",
       " 12  Related articles Glossary of artificial intell...\n",
       " 13                                                vte,\n",
       "                                                    0\n",
       " 0                            Part of a series on the\n",
       " 1                             Evolutionary algorithm\n",
       " 2  Artificial development Artificial life Cellula...\n",
       " 3                                  Genetic algorithm\n",
       " 4  Chromosome Clonal selection algorithm Crossove...\n",
       " 5                                Genetic programming\n",
       " 6  Cartesian genetic programming Linear genetic p...\n",
       " 7                                                vte,\n",
       "           Articles related to Artificial intelligence  \\\n",
       " 0   vteJohn McCarthy Artificial intelligence Circu...   \n",
       " 1                                    vteJohn McCarthy   \n",
       " 2   Artificial intelligence Circumscription Dartmo...   \n",
       " 3                               vtePhilosophy of mind   \n",
       " 4                                            Theories   \n",
       " ..                                                ...   \n",
       " 87  vteSubfields of and cyberneticians involved in...   \n",
       " 88                                          Subfields   \n",
       " 89                                     Cyberneticians   \n",
       " 90           vteGlossaries of science and engineering   \n",
       " 91  Aerospace engineering Agriculture Archaeology ...   \n",
       " \n",
       "         Articles related to Artificial intelligence.1 Unnamed: 2  \n",
       " 0   vteJohn McCarthy Artificial intelligence Circu...        NaN  \n",
       " 1                                    vteJohn McCarthy        NaN  \n",
       " 2   Artificial intelligence Circumscription Dartmo...        NaN  \n",
       " 3                               vtePhilosophy of mind        NaN  \n",
       " 4   Behaviorism (Radical) Biological naturalism Co...        NaN  \n",
       " ..                                                ...        ...  \n",
       " 87  vteSubfields of and cyberneticians involved in...        NaN  \n",
       " 88  Artificial intelligence Biological cybernetics...        NaN  \n",
       " 89  Alexander Lerner Alexey Lyapunov Alfred Radcli...        NaN  \n",
       " 90           vteGlossaries of science and engineering        NaN  \n",
       " 91  Aerospace engineering Agriculture Archaeology ...        NaN  \n",
       " \n",
       " [92 rows x 3 columns],\n",
       "                                     vteJohn McCarthy  \\\n",
       " 0  Artificial intelligence Circumscription Dartmo...   \n",
       " \n",
       "                                   vteJohn McCarthy.1  \n",
       " 0  Artificial intelligence Circumscription Dartmo...  ,\n",
       "                                vtePhilosophy of mind  \\\n",
       " 0                                           Theories   \n",
       " 1                                           Concepts   \n",
       " 2                                     Related topics   \n",
       " 3  Category Philosophers category Topic Project T...   \n",
       " \n",
       "                              vtePhilosophy of mind.1  \n",
       " 0  Behaviorism (Radical) Biological naturalism Co...  \n",
       " 1  Abstract object Artificial intelligence Chines...  \n",
       " 2  Metaphysics Philosophy of artificial intellige...  \n",
       " 3  Category Philosophers category Topic Project T...  ,\n",
       "                              vtePhilosophy of science  \\\n",
       " 0   Concepts Analysis Analytic–synthetic distincti...   \n",
       " 1                                            Concepts   \n",
       " 2                                Metatheoryof science   \n",
       " 3                                       Philosophy of   \n",
       " 4                                      Related topics   \n",
       " 5   Philosophers of science by eraAncient Plato Ar...   \n",
       " 6                      Philosophers of science by era   \n",
       " 7   Ancient Plato Aristotle Stoicism Epicureans Me...   \n",
       " 8                                             Ancient   \n",
       " 9                                            Medieval   \n",
       " 10                                       Early modern   \n",
       " 11                                        Late modern   \n",
       " 12                                       Contemporary   \n",
       " 13        Category  Philosophy portal  Science portal   \n",
       " \n",
       "                            vtePhilosophy of science.1  \n",
       " 0   Concepts Analysis Analytic–synthetic distincti...  \n",
       " 1   Analysis Analytic–synthetic distinction A prio...  \n",
       " 2   Coherentism Confirmation holism Constructive e...  \n",
       " 3   Physics thermal and statistical Motion Chemist...  \n",
       " 4   Alchemy Criticism of science Descriptive scien...  \n",
       " 5   Philosophers of science by eraAncient Plato Ar...  \n",
       " 6                      Philosophers of science by era  \n",
       " 7   Ancient Plato Aristotle Stoicism Epicureans Me...  \n",
       " 8                 Plato Aristotle Stoicism Epicureans  \n",
       " 9   Averroes Avicenna Roger Bacon William of Ockha...  \n",
       " 10  Francis Bacon Thomas Hobbes René Descartes Gal...  \n",
       " 11  Immanuel Kant Friedrich Schelling William Whew...  \n",
       " 12  Alfred North Whitehead Bertrand Russell Albert...  \n",
       " 13        Category  Philosophy portal  Science portal  ,\n",
       "                       0                                                  1\n",
       " 0              Concepts  Analysis Analytic–synthetic distinction A prio...\n",
       " 1  Metatheoryof science  Coherentism Confirmation holism Constructive e...\n",
       " 2         Philosophy of  Physics thermal and statistical Motion Chemist...\n",
       " 3        Related topics  Alchemy Criticism of science Descriptive scien...,\n",
       "                       Philosophers of science by era  \\\n",
       " 0  Ancient Plato Aristotle Stoicism Epicureans Me...   \n",
       " 1                                            Ancient   \n",
       " 2                                           Medieval   \n",
       " 3                                       Early modern   \n",
       " 4                                        Late modern   \n",
       " 5                                       Contemporary   \n",
       " \n",
       "                     Philosophers of science by era.1  \n",
       " 0  Ancient Plato Aristotle Stoicism Epicureans Me...  \n",
       " 1                Plato Aristotle Stoicism Epicureans  \n",
       " 2  Averroes Avicenna Roger Bacon William of Ockha...  \n",
       " 3  Francis Bacon Thomas Hobbes René Descartes Gal...  \n",
       " 4  Immanuel Kant Friedrich Schelling William Whew...  \n",
       " 5  Alfred North Whitehead Bertrand Russell Albert...  ,\n",
       "               0                                                  1\n",
       " 0       Ancient                Plato Aristotle Stoicism Epicureans\n",
       " 1      Medieval  Averroes Avicenna Roger Bacon William of Ockha...\n",
       " 2  Early modern  Francis Bacon Thomas Hobbes René Descartes Gal...\n",
       " 3   Late modern  Immanuel Kant Friedrich Schelling William Whew...\n",
       " 4  Contemporary  Alfred North Whitehead Bertrand Russell Albert...,\n",
       "   vteEvolutionary computation  \\\n",
       " 0                 Main Topics   \n",
       " 1                  Algorithms   \n",
       " 2          Related techniques   \n",
       " 3       Metaheuristic methods   \n",
       " 4              Related topics   \n",
       " 5                    Journals   \n",
       " \n",
       "                        vteEvolutionary computation.1  \n",
       " 0  Convergence (evolutionary computing) Evolution...  \n",
       " 1  Cellular evolutionary algorithm Covariance Mat...  \n",
       " 2  Swarm intelligence Ant colony optimization Bee...  \n",
       " 3  Grey Wolf Optimizer Firefly algorithm Harmony ...  \n",
       " 4  Artificial development Artificial intelligence...  \n",
       " 5                 Evolutionary Computation (journal)  ,\n",
       "                           vteDifferentiable computing  \\\n",
       " 0                                             General   \n",
       " 1                                            Concepts   \n",
       " 2                               Programming languages   \n",
       " 3                                         Application   \n",
       " 4                                            Hardware   \n",
       " 5                                    Software library   \n",
       " 6                                      Implementation   \n",
       " 7                                        Audio-visual   \n",
       " 8                                              Verbal   \n",
       " 9                                          Decisional   \n",
       " 10                                             People   \n",
       " 11                                      Organizations   \n",
       " 12  Portals Computer programming Technology  Categ...   \n",
       " \n",
       "                         vteDifferentiable computing.1  \\\n",
       " 0   Differentiable programming Neural Turing machi...   \n",
       " 1   Gradient descent SGD Clustering Regression Ove...   \n",
       " 2                                        Python Julia   \n",
       " 3   Machine learning Artificial neural network Dee...   \n",
       " 4                     IPU TPU VPU Memristor SpiNNaker   \n",
       " 5                     TensorFlow PyTorch Keras Theano   \n",
       " 6   Audio-visual AlexNet WaveNet Human image synth...   \n",
       " 7   AlexNet WaveNet Human image synthesis HWR OCR ...   \n",
       " 8   Word2vec Transformer BERT NMT Project Debater ...   \n",
       " 9   AlphaGo Q-learning SARSA OpenAI Five Self-driv...   \n",
       " 10  Alex Graves Ian Goodfellow Yoshua Bengio Geoff...   \n",
       " 11   DeepMind OpenAI MIT CSAIL Mila Google Brain FAIR   \n",
       " 12  Portals Computer programming Technology  Categ...   \n",
       " \n",
       "                         vteDifferentiable computing.2  \n",
       " 0                                                 NaN  \n",
       " 1                                                 NaN  \n",
       " 2                                                 NaN  \n",
       " 3                                                 NaN  \n",
       " 4                                                 NaN  \n",
       " 5                                                 NaN  \n",
       " 6                                                 NaN  \n",
       " 7                                                 NaN  \n",
       " 8                                                 NaN  \n",
       " 9                                                 NaN  \n",
       " 10                                                NaN  \n",
       " 11                                                NaN  \n",
       " 12  Portals Computer programming Technology  Categ...  ,\n",
       "               0                                                  1\n",
       " 0  Audio-visual  AlexNet WaveNet Human image synthesis HWR OCR ...\n",
       " 1        Verbal  Word2vec Transformer BERT NMT Project Debater ...\n",
       " 2    Decisional  AlphaGo Q-learning SARSA OpenAI Five Self-driv...,\n",
       "         vteComputable knowledge  \\\n",
       " 0            Topics andconcepts   \n",
       " 1  Proposals andimplementations   \n",
       " 2                    In fiction   \n",
       " \n",
       "                            vteComputable knowledge.1  \n",
       " 0  Alphabet of human thought Authority control Au...  \n",
       " 1  Zairja Ars Magna (1300) An Essay towards a Rea...  \n",
       " 2  The Engine (Gulliver's Travels, 1726) Joe (\"A ...  ,\n",
       "                                   vteComputer science  \\\n",
       " 0   Note: This template roughly follows the 2012 A...   \n",
       " 1                                            Hardware   \n",
       " 2                       Computer systems organization   \n",
       " 3                                            Networks   \n",
       " 4                               Software organization   \n",
       " 5                        Software notations and tools   \n",
       " 6                                Software development   \n",
       " 7                               Theory of computation   \n",
       " 8                                          Algorithms   \n",
       " 9                            Mathematics of computing   \n",
       " 10                                Information systems   \n",
       " 11                                           Security   \n",
       " 12                         Human–computer interaction   \n",
       " 13                                        Concurrency   \n",
       " 14                            Artificial intelligence   \n",
       " 15                                   Machine learning   \n",
       " 16                                           Graphics   \n",
       " 17                                  Applied computing   \n",
       " 18             Category  Outline WikiProject  Commons   \n",
       " \n",
       "                                 vteComputer science.1  \\\n",
       " 0   Note: This template roughly follows the 2012 A...   \n",
       " 1   Printed circuit board Peripheral Integrated ci...   \n",
       " 2   Computer architecture Embedded system Real-tim...   \n",
       " 3   Network architecture Network protocol Network ...   \n",
       " 4   Interpreter Middleware Virtual machine Operati...   \n",
       " 5   Programming paradigm Programming language Comp...   \n",
       " 6   Control variable Software development process ...   \n",
       " 7   Model of computation Formal language Automata ...   \n",
       " 8   Algorithm design Analysis of algorithms Algori...   \n",
       " 9   Discrete mathematics Probability Statistics Ma...   \n",
       " 10  Database management system Information storage...   \n",
       " 11  Cryptography Formal methods Security services ...   \n",
       " 12  Interaction design Social computing Ubiquitous...   \n",
       " 13  Concurrent computing Parallel computing Distri...   \n",
       " 14  Natural language processing Knowledge represen...   \n",
       " 15  Supervised learning Unsupervised learning Rein...   \n",
       " 16  Animation Rendering Image manipulation Graphic...   \n",
       " 17  E-commerce Enterprise software Computational m...   \n",
       " 18             Category  Outline WikiProject  Commons   \n",
       " \n",
       "                                 vteComputer science.2  \n",
       " 0   Note: This template roughly follows the 2012 A...  \n",
       " 1                                                 NaN  \n",
       " 2                                                 NaN  \n",
       " 3                                                 NaN  \n",
       " 4                                                 NaN  \n",
       " 5                                                 NaN  \n",
       " 6                                                 NaN  \n",
       " 7                                                 NaN  \n",
       " 8                                                 NaN  \n",
       " 9                                                 NaN  \n",
       " 10                                                NaN  \n",
       " 11                                                NaN  \n",
       " 12                                                NaN  \n",
       " 13                                                NaN  \n",
       " 14                                                NaN  \n",
       " 15                                                NaN  \n",
       " 16                                                NaN  \n",
       " 17                                                NaN  \n",
       " 18             Category  Outline WikiProject  Commons  ,\n",
       "         vteEmerging technologies  \\\n",
       " 0                         Fields   \n",
       " 1  Information andcommunications   \n",
       " 2                         Topics   \n",
       " 3                 Category  List   \n",
       " \n",
       "                           vteEmerging technologies.1  \n",
       " 0  Information andcommunications Ambient intellig...  \n",
       " 1  Ambient intelligence Internet of things Artifi...  \n",
       " 2  Collingridge dilemma Differential technologica...  \n",
       " 3                                     Category  List  ,\n",
       "                                0  \\\n",
       " 0  Information andcommunications   \n",
       " \n",
       "                                                    1  \n",
       " 0  Ambient intelligence Internet of things Artifi...  ,\n",
       "          vteRobotics                                      vteRobotics.1  \\\n",
       " 0      Main articles  Outline Glossary Index History Geography Hall ...   \n",
       " 1              Types  Anthropomorphic Humanoid Android Cyborg Claytr...   \n",
       " 2    Classifications  Biorobotics Unmanned vehicle aerial ground Mob...   \n",
       " 3         Locomotion  Tracks Walking Hexapod Climbing Electric unicy...   \n",
       " 4           Research  Evolutionary Kits Simulator Suite Open-source ...   \n",
       " 5            Related  Powered exoskeleton Technological unemployment...   \n",
       " 6  Category  Outline                                  Category  Outline   \n",
       " \n",
       "        vteRobotics.2  \n",
       " 0                NaN  \n",
       " 1                NaN  \n",
       " 2                NaN  \n",
       " 3                NaN  \n",
       " 4                NaN  \n",
       " 5                NaN  \n",
       " 6  Category  Outline  ,\n",
       "   vteExistential risk from artificial intelligence  \\\n",
       " 0                                         Concepts   \n",
       " 1                                    Organizations   \n",
       " 2                                           People   \n",
       " 3                                            Other   \n",
       " 4                                         Category   \n",
       " \n",
       "   vteExistential risk from artificial intelligence.1  \n",
       " 0  Accelerating change AI box AI takeover Control...  \n",
       " 1  Allen Institute for AI Center for Applied Rati...  \n",
       " 2  Scott Alexander Nick Bostrom Eric Drexler Sam ...  \n",
       " 3  Artificial intelligence as a global catastroph...  \n",
       " 4                                           Category  ,\n",
       "   vteSubfields of and cyberneticians involved in cybernetics  \\\n",
       " 0                                          Subfields           \n",
       " 1                                     Cyberneticians           \n",
       " \n",
       "   vteSubfields of and cyberneticians involved in cybernetics.1  \n",
       " 0  Artificial intelligence Biological cybernetics...            \n",
       " 1  Alexander Lerner Alexey Lyapunov Alfred Radcli...            ,\n",
       "             vteGlossaries of science and engineering  \\\n",
       " 0  Aerospace engineering Agriculture Archaeology ...   \n",
       " \n",
       "           vteGlossaries of science and engineering.1  \n",
       " 0  Aerospace engineering Agriculture Archaeology ...  ,\n",
       "     Authority control                      Authority control.1\n",
       " 0             General      Integrated Authority File (Germany)\n",
       " 1  National libraries  Spain France (data) United States Japan\n",
       " 2               Other                       Microsoft Academic]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_lists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cffccd8",
   "metadata": {},
   "source": [
    "## Extract Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f117748",
   "metadata": {},
   "source": [
    "Twitter tweets can be extracted and fed into a NLP model to get a wider public view. We can use the tweepy library to extract the tweets for our target keywords.\n",
    "\n",
    "Let’s assume we are interested in a company or certain Twitter members, we can use the Tweepy library to extract the required tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6793289",
   "metadata": {},
   "source": [
    "The first stage is to generate the required tokens and secret security information:\n",
    "\n",
    "* Navigate to https://apps.twitter.com/ and ‘Create New App’\n",
    "* Choose Create your Twitter Application, fill in the details and you will get your token from ‘Keys and Access Tokens’ tab.\n",
    "\n",
    "\n",
    "Lastly use the following code to extract the tweets. Let’s assume you want to extract last 5 tweets about FinTechExplained and MachineLearning:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433c3835",
   "metadata": {},
   "source": [
    "### Import the Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3664cd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from tweepy.streaming import StreamListener\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy import Stream"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e2dc35",
   "metadata": {},
   "source": [
    "### Get the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5a1fc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter the details below\n",
    "# auth = tweepy.auth.OAuthHandler(enter_key_consumer, enter_secret_consumer)\n",
    "\n",
    "# auth.set_access_token(token, secret)\n",
    "\n",
    "# api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86175c1d",
   "metadata": {},
   "source": [
    "### Get Tweets and Print Them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fa9736f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweets(api, keywords, count):\n",
    "    return api.search(q=keywords, result_type='recent', lang='en', count=count)\n",
    "\n",
    "# tweets = get_tweets(api, ['FinTechExplained','MachineLearning'], 5)\n",
    "\n",
    "# #Print Output\n",
    "# for tweet in tweets:\n",
    "#     print(tweet.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f59e5c9",
   "metadata": {},
   "source": [
    "The tweet object has a number of additional properties including place, friends count, followers count, screen name and so on. We can also extract tweets from a specific user."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17140a4f",
   "metadata": {},
   "source": [
    "## Extract Text From A HTML Webpage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15def8ea",
   "metadata": {},
   "source": [
    "For HTML scarping, use BeautifulSoap library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c044d7f4",
   "metadata": {},
   "source": [
    "### Step 1: Install BeautifulSoap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29409184",
   "metadata": {},
   "source": [
    "### Step 2: Use the required classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f964b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12226c4c",
   "metadata": {},
   "source": [
    "### Step 3: Pass Url and Parse HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a4c4e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://en.wikipedia.org/wiki/Natural_language_processing\"\n",
    "all_html = BeautifulSoup(urlopen(url), 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7e584c",
   "metadata": {},
   "source": [
    "Use find() method to get the text of the required tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e207665",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = all_html.find_all('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26a66c60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p><b>Natural language processing</b> (<b>NLP</b>) is a subfield of <a href=\"/wiki/Linguistics\" title=\"Linguistics\">linguistics</a>, <a href=\"/wiki/Computer_science\" title=\"Computer science\">computer science</a>, and <a href=\"/wiki/Artificial_intelligence\" title=\"Artificial intelligence\">artificial intelligence</a> concerned with the interactions between computers and human language, in particular how to program computers to process and analyze large amounts of <a href=\"/wiki/Natural_language\" title=\"Natural language\">natural language</a> data.  The goal is a computer capable of \"understanding\" the contents of documents, including the contextual nuances of the language within them. The technology can then accurately extract information and insights contained in the documents as well as categorize and organize the documents themselves.\n",
       " </p>,\n",
       " <p>Challenges in natural language processing frequently involve <a href=\"/wiki/Speech_recognition\" title=\"Speech recognition\">speech recognition</a>, <a href=\"/wiki/Natural-language_understanding\" title=\"Natural-language understanding\">natural language understanding</a>, and <a href=\"/wiki/Natural-language_generation\" title=\"Natural-language generation\">natural language generation</a>.\n",
       " </p>,\n",
       " <p>Natural language processing has its roots in the 1950s. Already in 1950, <a href=\"/wiki/Alan_Turing\" title=\"Alan Turing\">Alan Turing</a> published an article titled \"<a href=\"/wiki/Computing_Machinery_and_Intelligence\" title=\"Computing Machinery and Intelligence\">Computing Machinery and Intelligence</a>\" which proposed what is now called the <a href=\"/wiki/Turing_test\" title=\"Turing test\">Turing test</a> as a criterion of intelligence, a task that involves the automated interpretation and generation of natural language, but at the time not articulated as a problem separate from artificial intelligence.\n",
       " </p>,\n",
       " <p>The premise of symbolic NLP is well-summarized by <a href=\"/wiki/John_Searle\" title=\"John Searle\">John Searle</a>'s <a href=\"/wiki/Chinese_room\" title=\"Chinese room\">Chinese room</a> experiment: Given a collection of rules (e.g., a Chinese phrasebook, with questions and matching answers), the computer emulates natural language understanding (or other NLP tasks) by applying those rules to the data it is confronted with.\n",
       " </p>,\n",
       " <p>Up to the 1980s, most natural language processing systems were based on complex sets of hand-written rules.  Starting in the late 1980s, however, there was a revolution in natural language processing with the introduction of <a href=\"/wiki/Machine_learning\" title=\"Machine learning\">machine learning</a> algorithms for language processing.  This was due to both the steady increase in computational power (see <a href=\"/wiki/Moore%27s_law\" title=\"Moore's law\">Moore's law</a>) and the gradual lessening of the dominance of <a href=\"/wiki/Noam_Chomsky\" title=\"Noam Chomsky\">Chomskyan</a> theories of linguistics (e.g. <a href=\"/wiki/Transformational_grammar\" title=\"Transformational grammar\">transformational grammar</a>), whose theoretical underpinnings discouraged the sort of <a href=\"/wiki/Corpus_linguistics\" title=\"Corpus linguistics\">corpus linguistics</a> that underlies the machine-learning approach to language processing.<sup class=\"reference\" id=\"cite_ref-6\"><a href=\"#cite_note-6\">[6]</a></sup>\n",
       " </p>,\n",
       " <p>In the 2010s, <a class=\"mw-redirect\" href=\"/wiki/Representation_learning\" title=\"Representation learning\">representation learning</a> and <a href=\"/wiki/Deep_learning\" title=\"Deep learning\">deep neural network</a>-style machine learning methods became widespread in natural language processing, due in part to a flurry of results showing that such techniques<sup class=\"reference\" id=\"cite_ref-goldberg:nnlp17_7-0\"><a href=\"#cite_note-goldberg:nnlp17-7\">[7]</a></sup><sup class=\"reference\" id=\"cite_ref-goodfellow:book16_8-0\"><a href=\"#cite_note-goodfellow:book16-8\">[8]</a></sup> can achieve state-of-the-art results in many natural language tasks, for example in language modeling,<sup class=\"reference\" id=\"cite_ref-jozefowicz:lm16_9-0\"><a href=\"#cite_note-jozefowicz:lm16-9\">[9]</a></sup> parsing,<sup class=\"reference\" id=\"cite_ref-choe:emnlp16_10-0\"><a href=\"#cite_note-choe:emnlp16-10\">[10]</a></sup><sup class=\"reference\" id=\"cite_ref-vinyals:nips15_11-0\"><a href=\"#cite_note-vinyals:nips15-11\">[11]</a></sup> and many others. This is increasingly important in medicine and healthcare, where NLP is being used to analyze notes and text in electronic health records that would otherwise be inaccessible for study when seeking to improve care.<sup class=\"reference\" id=\"cite_ref-12\"><a href=\"#cite_note-12\">[12]</a></sup>\n",
       " </p>,\n",
       " <p>In the early days, many language-processing systems were designed by symbolic methods, i.e., the hand-coding of a set of rules, coupled with a dictionary lookup:<sup class=\"reference\" id=\"cite_ref-winograd:shrdlu71_13-0\"><a href=\"#cite_note-winograd:shrdlu71-13\">[13]</a></sup><sup class=\"reference\" id=\"cite_ref-schank77_14-0\"><a href=\"#cite_note-schank77-14\">[14]</a></sup> such as by writing grammars or devising heuristic rules for <a href=\"/wiki/Stemming\" title=\"Stemming\">stemming</a>.\n",
       " </p>,\n",
       " <p>More recent systems based on <a href=\"/wiki/Machine_learning\" title=\"Machine learning\">machine-learning</a> algorithms have many advantages over hand-produced rules: \n",
       " </p>,\n",
       " <p>Despite the popularity of machine learning in NLP research, symbolic methods are still (2020) commonly used:\n",
       " </p>,\n",
       " <p>Since the so-called \"statistical revolution\"<sup class=\"reference\" id=\"cite_ref-johnson:eacl:ilcl09_15-0\"><a href=\"#cite_note-johnson:eacl:ilcl09-15\">[15]</a></sup><sup class=\"reference\" id=\"cite_ref-resnik:langlog11_16-0\"><a href=\"#cite_note-resnik:langlog11-16\">[16]</a></sup> in the late 1980s and mid-1990s, much natural language processing research has relied heavily on machine learning. The machine-learning paradigm calls instead for using <a href=\"/wiki/Statistical_inference\" title=\"Statistical inference\">statistical inference</a> to automatically learn such rules through the analysis of large <i><a href=\"/wiki/Text_corpus\" title=\"Text corpus\">corpora</a></i> (the plural form of <i>corpus</i>, is a set of documents, possibly with human or computer annotations) of typical real-world examples.\n",
       " </p>,\n",
       " <p>Many different classes of machine-learning algorithms have been applied to natural-language-processing tasks. These algorithms take as input a large set of \"features\" that are generated from the input data. Increasingly, however, research has focused on <a class=\"mw-redirect\" href=\"/wiki/Statistical_models\" title=\"Statistical models\">statistical models</a>, which make soft, <a class=\"mw-redirect\" href=\"/wiki/Probabilistic\" title=\"Probabilistic\">probabilistic</a> decisions based on attaching <a class=\"mw-redirect\" href=\"/wiki/Real-valued\" title=\"Real-valued\">real-valued</a> weights to each input feature (complex-valued <a href=\"/wiki/Word_embedding\" title=\"Word embedding\">embeddings</a>,<sup class=\"reference\" id=\"cite_ref-17\"><a href=\"#cite_note-17\">[17]</a></sup> and neural networks in general have also been proposed, for e.g. speech<sup class=\"reference\" id=\"cite_ref-18\"><a href=\"#cite_note-18\">[18]</a></sup>). Such models have the advantage that they can express the relative certainty of many different possible answers rather than only one, producing more reliable results when such a model is included as a component of a larger system.\n",
       " </p>,\n",
       " <p>Some of the earliest-used machine learning algorithms, such as <a href=\"/wiki/Decision_tree\" title=\"Decision tree\">decision trees</a>, produced systems of hard if-then rules similar to existing hand-written rules.  However, <a class=\"mw-redirect\" href=\"/wiki/Part_of_speech_tagging\" title=\"Part of speech tagging\">part-of-speech tagging</a> introduced the use of <a class=\"mw-redirect\" href=\"/wiki/Hidden_Markov_models\" title=\"Hidden Markov models\">hidden Markov models</a> to natural language processing, and increasingly, research has focused on <a class=\"mw-redirect\" href=\"/wiki/Statistical_models\" title=\"Statistical models\">statistical models</a>, which make soft, <a class=\"mw-redirect\" href=\"/wiki/Probabilistic\" title=\"Probabilistic\">probabilistic</a> decisions based on attaching <a class=\"mw-redirect\" href=\"/wiki/Real-valued\" title=\"Real-valued\">real-valued</a> weights to the features making up the input data. The <a href=\"/wiki/Cache_language_model\" title=\"Cache language model\">cache language models</a> upon which many <a href=\"/wiki/Speech_recognition\" title=\"Speech recognition\">speech recognition</a> systems now rely are examples of such statistical models.  Such models are generally more robust when given unfamiliar input, especially input that contains errors (as is very common for real-world data), and produce more reliable results when integrated into a larger system comprising multiple subtasks.\n",
       " </p>,\n",
       " <p>Since the neural turn, statistical methods in NLP research have been largely replaced by neural networks. However, they continue to be relevant for contexts in which statistical interpretability and transparency is required.\n",
       " </p>,\n",
       " <p>A major drawback of statistical methods is that they require elaborate feature engineering. Since 2015,<sup class=\"reference\" id=\"cite_ref-19\"><a href=\"#cite_note-19\">[19]</a></sup> the field has thus largely abandoned statistical methods and shifted to <a href=\"/wiki/Neural_network\" title=\"Neural network\">neural networks</a> for machine learning. Popular techniques include the use of <a href=\"/wiki/Word_embedding\" title=\"Word embedding\">word embeddings</a> to capture semantic properties of words, and an increase in end-to-end learning of a higher-level task (e.g., question answering) instead of relying on a pipeline of separate intermediate tasks (e.g., part-of-speech tagging and dependency parsing). In some areas, this shift has entailed substantial changes in how NLP systems are designed, such that deep neural network-based approaches may be viewed as a new paradigm distinct from statistical natural language processing. For instance, the term <i><a href=\"/wiki/Neural_machine_translation\" title=\"Neural machine translation\">neural machine translation</a></i> (NMT) emphasizes the fact that deep learning-based approaches to machine translation directly learn <a href=\"/wiki/Seq2seq\" title=\"Seq2seq\">sequence-to-sequence</a> transformations, obviating the need for intermediate steps such as word alignment and language modeling that was used in <a href=\"/wiki/Statistical_machine_translation\" title=\"Statistical machine translation\">statistical machine translation</a> (SMT). Latest works tend to use non-technical structure of a given task to build proper neural network.<sup class=\"reference\" id=\"cite_ref-20\"><a href=\"#cite_note-20\">[20]</a></sup>\n",
       " </p>,\n",
       " <p>The following is a list of some of the most commonly researched tasks in natural language processing. Some of these tasks have direct real-world applications, while others more commonly serve as subtasks that are used to aid in solving larger tasks.\n",
       " </p>,\n",
       " <p>Though natural language processing tasks are closely intertwined, they can be subdivided into categories for convenience. A coarse division is given below.\n",
       " </p>,\n",
       " <p>Based on long-standing trends in the field, it is possible to extrapolate future directions of NLP. As of 2020, three trends among the topics of the long-standing series of CoNLL Shared Tasks can be observed:<sup class=\"reference\" id=\"cite_ref-36\"><a href=\"#cite_note-36\">[36]</a></sup>\n",
       " </p>,\n",
       " <p>Most higher-level NLP applications involve aspects that emulate intelligent behaviour and apparent comprehension of natural language. More broadly speaking, the technical operationalization of increasingly advanced aspects of cognitive behaviour represents one of the developmental trajectories of NLP (see trends among CoNLL shared tasks above).\n",
       " </p>,\n",
       " <p><a href=\"/wiki/Cognition\" title=\"Cognition\">Cognition</a> refers to \"the mental action or process of acquiring knowledge and understanding through thought, experience, and the senses.\"<sup class=\"reference\" id=\"cite_ref-37\"><a href=\"#cite_note-37\">[37]</a></sup> <a href=\"/wiki/Cognitive_science\" title=\"Cognitive science\">Cognitive science</a> is the interdisciplinary, scientific study of the mind and its processes.<sup class=\"reference\" id=\"cite_ref-38\"><a href=\"#cite_note-38\">[38]</a></sup> <a href=\"/wiki/Cognitive_linguistics\" title=\"Cognitive linguistics\">Cognitive linguistics</a> is an interdisciplinary branch of linguistics, combining knowledge and research from both psychology and linguistics.<sup class=\"reference\" id=\"cite_ref-39\"><a href=\"#cite_note-39\">[39]</a></sup> Especially during the age of <a href=\"#Symbolic_NLP_(1950s_-_early_1990s)\">symbolic NLP</a>, the area of computational linguistics maintained strong ties with cognitive studies.\n",
       " </p>,\n",
       " <p>As an example, <a href=\"/wiki/George_Lakoff\" title=\"George Lakoff\">George Lakoff</a> offers a methodology to build natural language processing (NLP) algorithms through the perspective of <a href=\"/wiki/Cognitive_science\" title=\"Cognitive science\">cognitive science</a>, along with the findings of <a href=\"/wiki/Cognitive_linguistics\" title=\"Cognitive linguistics\">cognitive linguistics</a>,<sup class=\"reference\" id=\"cite_ref-40\"><a href=\"#cite_note-40\">[40]</a></sup> with two defining aspects:\n",
       " </p>,\n",
       " <p>Ties with cognitive linguistics are part of the historical heritage of NLP, but they have been less frequently addressed since the statistical turn during the 1990s. Nevertheless, approaches to develop cognitive models towards technically operationalizable frameworks have been pursued in the context of various frameworks, e.g., of cognitive grammar,<sup class=\"reference\" id=\"cite_ref-42\"><a href=\"#cite_note-42\">[42]</a></sup> functional grammar,<sup class=\"reference\" id=\"cite_ref-43\"><a href=\"#cite_note-43\">[43]</a></sup> construction grammar,<sup class=\"reference\" id=\"cite_ref-44\"><a href=\"#cite_note-44\">[44]</a></sup> computational psycholinguistics and cognitive neuroscience (e.g., <a href=\"/wiki/ACT-R\" title=\"ACT-R\">ACT-R</a>), however, with limited uptake in mainstream NLP (as measured by presence on major conferences<sup class=\"reference\" id=\"cite_ref-45\"><a href=\"#cite_note-45\">[45]</a></sup> of the <a href=\"/wiki/Association_for_Computational_Linguistics\" title=\"Association for Computational Linguistics\">ACL</a>). More recently, ideas of cognitive NLP have been revived as an approach to achieve <a href=\"/wiki/Explainable_artificial_intelligence\" title=\"Explainable artificial intelligence\">explainability</a>, e.g., under the notion of \"cognitive AI\".<sup class=\"reference\" id=\"cite_ref-46\"><a href=\"#cite_note-46\">[46]</a></sup> Likewise, ideas of cognitive NLP are inherent to neural models multimodal NLP (although rarely made explicit).<sup class=\"reference\" id=\"cite_ref-47\"><a href=\"#cite_note-47\">[47]</a></sup>\n",
       " </p>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc8f72d",
   "metadata": {},
   "source": [
    "## Read A Word Document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb3ed52",
   "metadata": {},
   "source": [
    "We can use the docx libary to read and extract text from the word documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "944bd26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import Document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88336a6d",
   "metadata": {},
   "source": [
    "### Open File and Extract Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b522db3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything we express (either verbally or in written) carries huge amounts of information. The topic we choose, our tone, our selection of words, everything adds some type of information that can be interpreted and value extracted from it. In theory, we can understand and even predict human behaviour using that information.\n",
      "But there is a problem: one person may generate hundreds or thousands of words in a declaration, each sentence with its corresponding complexity. If you want to scale and analyze several hundreds, thousands or millions of people or declarations in a given geography, then the situation is unmanageable.\n",
      "Data generated from conversations, declarations or even tweets are examples of unstructured data. Unstructured data doesn’t fit neatly into the traditional row and column structure of relational databases, and represent the vast majority of data available in the actual world. It is messy and hard to manipulate. Nevertheless, thanks to the advances in disciplines like machine learning a big revolution is going on regarding this topic. Nowadays it is no longer about trying to interpret a text or speech based on its keywords (the old fashioned mechanical way), but about understanding the meaning behind those words (the cognitive way). This way it is possible to detect figures of speech like irony, or even perform sentiment analysis.\n",
      "Natural Language Processing or NLP is a field of Artificial Intelligence that gives the machines the ability to read, understand and derive meaning from human languages.\n",
      "It is a discipline that focuses on the interaction between data science and human language, and is scaling to lots of industries. Today NLP is booming thanks to the huge improvements in the access to data and the increase in computational power, which are allowing practitioners to achieve meaningful results in areas like healthcare, media, finance and human resources, among others.\n",
      "Use Cases of NLP\n",
      "In simple terms, NLP represents the automatic handling of natural human language like speech or text, and although the concept itself is fascinating, the real value behind this technology comes from the use cases.\n",
      "NLP can help you with lots of tasks and the fields of application just seem to increase on a daily basis. Let’s mention some examples:\n",
      "NLP enables the recognition and prediction of diseases based on electronic health records and patient’s own speech. This capability is being explored in health conditions that go from cardiovascular diseases to depression and even schizophrenia. For example, Amazon Comprehend Medical is a service that uses NLP to , medications and treatment outcomes from patient notes, clinical trial reports and other electronic health records.\n",
      "Organizations can determine what customers are saying about a service or product by identifying and extracting information in sources like social media. This  can provide a lot of information about customers choices and their decision drivers.\n",
      " that works like a personalized search engine by learning all about you and then remind you of a name, a song, or anything you can’t remember the moment you need it to.\n",
      "Companies like Yahoo and Google filter and classify your emails with NLP by analyzing text in emails that flow through their servers and stopping spam before they even enter your inbox.\n",
      "To help identifying fake news, the  developed a new system to determine if a source is accurate or politically biased, detecting if a news source can be trusted or not.\n",
      "Amazon’s Alexa and Apple’s Siri are examples of intelligent voice driven interfaces that use NLP to respond to vocal prompts and do everything like find a particular shop, tell us the weather forecast, suggest the best route to the office or turn on the lights at home.\n",
      "Having an insight into what is happening and what people are talking about can be very valuable to . NLP is being used to track news, reports, comments about possible mergers between companies, everything can be then incorporated into a trading algorithm to generate massive profits. Remember: buy the rumor, sell the news.\n",
      "NLP is also being used in both the search and selection phases of , identifying the skills of potential hires and also spotting prospects before they become active on the job market.\n",
      "Powered by IBM Watson NLP technology,  developed a platform to automate routine litigation tasks and help legal teams save time, drive down costs and shift strategic focus.\n",
      "NLP is particularly booming in the healthcare industry. This technology is improving care delivery, disease diagnosis and bringing costs down while healthcare organizations are going through a growing adoption of electronic health records. The fact that clinical documentation can be improved means that patients can be better understood and benefited through better healthcare. The goal should be to optimize their experience, and several organizations are already working on this.\n",
      "\n",
      "\n",
      "Number of publications containing the sentence “natural language processing” in PubMed in the period 1978–2018. As of 2018, PubMed comprised more than 29 million citations for biomedical literature\n",
      "Companies like  are making huge improvements in the treatment of Alzheimer’s disease by monitoring cognitive impairment through speech and they can also support clinical trials and studies for a wide range of central nervous system disorders. Following a similar approach, Stanford University developed , a chatbot therapist with the aim of helping people with anxiety and other disorders.\n",
      "But serious  is around the subject. A couple of years ago Microsoft demonstrated that by analyzing large samples of search engine queries, they could  even before they have received a diagnosis of the disease. How would users react to such diagnosis? And what would happen if you were tested as a false positive? (meaning that you can be diagnosed with the disease even though you don’t have it). This recalls the case of Google Flu Trends which in 2009 was announced as being able to predict influenza but later on vanished due to its low accuracy and inability to meet its projected rates.\n",
      "NLP may be the key to an effective clinical support in the future, but there are still many challenges to face in the short term.\n",
      "Basic NLP to impress your non-NLP friends\n",
      "The main drawbacks we face these days with NLP relate to the fact that language is very tricky. The process of understanding and manipulating language is extremely complex, and for this reason it is common to use different techniques to handle different challenges before binding everything together. Programming languages like Python or R are highly used to perform these techniques, but before diving into code lines (that will be the topic of a different article), it’s important to understand the concepts beneath them. Let’s summarize and explain some of the most frequently used algorithms in NLP when defining the vocabulary of terms:\n",
      "Bag of Words\n",
      "Is a commonly used model that allows you to count all words in a piece of text. Basically it creates an occurrence matrix for the sentence or document, disregarding grammar and word order. These word frequencies or occurrences are then used as features for training a classifier.\n",
      "To bring a short example I took the first sentence of the song “Across the Universe” from The Beatles:\n",
      "Words are flowing out like endless rain into a paper cup,\n",
      "They slither while they pass, they slip away across the universe\n",
      "Now let’s count the words:\n",
      "\n",
      "\n",
      "This approach may reflect several downsides like the absence of semantic meaning and context, and the facts that stop words (like “the” or “a”) add noise to the analysis and some words are not weighted accordingly (“universe” weights less than the word “they”).\n",
      "To solve this problem, one approach is to rescale the frequency of words by how often they appear in all texts (not just the one we are analyzing) so that the scores for frequent words like “the”, that are also frequent across other texts, get penalized. This approach to scoring is called “Term Frequency — Inverse Document Frequency” (TFIDF), and improves the bag of words by weights. Through TFIDF frequent terms in the text are “rewarded” (like the word “they” in our example), but they also get “punished” if those terms are frequent in other texts we include in the algorithm too. On the contrary, this method highlights and “rewards” unique or rare terms considering all texts. Nevertheless, this approach still has no context nor semantics.\n",
      "Tokenization\n",
      "Is the process of segmenting running text into sentences and words. In essence, it’s the task of cutting a text into pieces called tokens, and at the same time throwing away certain characters, such as punctuation. Following our example, the result of tokenization would be:\n",
      "\n",
      "\n",
      "Pretty simple, right? Well, although it may seem quite basic in this case and also in languages like English that separate words by a blank space (called segmented languages) not all languages behave the same, and if you think about it, blank spaces alone are not sufficient enough even for English to perform proper tokenizations. Splitting on blank spaces may break up what should be considered as one token, as in the case of certain names (e.g. San Francisco or New York) or borrowed foreign phrases (e.g. laissez faire).\n",
      "Tokenization can remove punctuation too, easing the path to a proper word segmentation but also triggering possible complications. In the case of periods that follow abbreviation (e.g. dr.), the period following that abbreviation should be considered as part of the same token and not be removed.\n",
      "The tokenization process can be particularly problematic when dealing with biomedical text domains which contain lots of hyphens, parentheses, and other punctuation marks.\n",
      "For deeper details on tokenization, you can find a great explanation in .\n",
      "Stop Words Removal\n",
      "Includes getting rid of common language articles, pronouns and prepositions such as “and”, “the” or “to” in English. In this process some very common words that appear to provide little or no value to the NLP objective are filtered and excluded from the text to be processed, hence removing widespread and frequent terms that are not informative about the corresponding text.\n",
      "Stop words can be safely ignored by carrying out a lookup in a pre-defined list of keywords, freeing up database space and improving processing time.\n",
      "There is no universal list of stop words. These can be pre-selected or built from scratch. A potential approach is to begin by adopting pre-defined stop words and add words to the list later on. Nevertheless it seems that the general trend over the past time has been to go from the use of large standard stop word lists to the use of no lists at all.\n",
      "The thing is stop words removal can wipe out relevant information and modify the context in a given sentence. For example, if we are performing a sentiment analysis we might throw our algorithm off track if we remove a stop word like “not”. Under these conditions, you might select a minimal stop word list and add additional terms depending on your specific objective.\n",
      "Stemming\n",
      "Refers to the process of slicing the end or the beginning of words with the intention of removing affixes (lexical additions to the root of the word).\n",
      "Affixes that are attached at the beginning of the word are called prefixes (e.g. “astro” in the word “astrobiology”) and the ones attached at the end of the word are called suffixes (e.g. “ful” in the word “helpful”).\n",
      "The problem is that affixes can create or expand new forms of the same word (called inflectional affixes), or even create new words themselves (called derivational affixes). In English, prefixes are always derivational (the affix creates a new word as in the example of the prefix “eco” in the word “ecosystem”), but suffixes can be derivational (the affix creates a new word as in the example of the suffix “ist” in the word “guitarist”) or inflectional (the affix creates a new form of word as in the example of the suffix “er” in the word “faster”).\n",
      "Ok, so how can we tell the difference and chop the right bit?\n",
      "\n",
      "\n",
      "A possible approach is to consider a list of common affixes and rules (Python and R languages have different libraries containing affixes and methods) and perform stemming based on them, but of course this approach presents limitations. Since stemmers use algorithmics approaches, the result of the stemming process may not be an actual word or even change the word (and sentence) meaning. To offset this effect you can edit those predefined methods by adding or removing affixes and rules, but you must consider that you might be improving the performance in one area while producing a degradation in another one. Always look at the whole picture and test your model’s performance.\n",
      "So if stemming has serious limitations, why do we use it? First of all, it can be used to correct spelling errors from the tokens. Stemmers are simple to use and run very fast (they perform simple operations on a string), and if speed and performance are important in the NLP model, then stemming is certainly the way to go. Remember, we use it with the objective of improving our performance, not as a grammar exercise.\n",
      "Lemmatization\n",
      "Has the objective of reducing a word to its base form and grouping together different forms of the same word. For example, verbs in past tense are changed into present (e.g. “went” is changed to “go”) and synonyms are unified (e.g. “best” is changed to “good”), hence standardizing words with similar meaning to their root. Although it seems closely related to the stemming process, lemmatization uses a different approach to reach the root forms of words.\n",
      "Lemmatization resolves words to their dictionary form (known as lemma) for which it requires detailed dictionaries in which the algorithm can look into and link words to their corresponding lemmas.\n",
      "For example, the words “running”, “runs” and “ran” are all forms of the word “run”, so “run” is the lemma of all the previous words.\n",
      "\n",
      "\n",
      "Lemmatization also takes into consideration the context of the word in order to solve other problems like disambiguation, which means it can discriminate between identical words that have different meanings depending on the specific context. Think about words like “bat” (which can correspond to the animal or to the metal/wooden club used in baseball) or “bank” (corresponding to the financial institution or to the land alongside a body of water). By providing a part-of-speech parameter to a word ( whether it is a noun, a verb, and so on) it’s possible to define a role for that word in the sentence and remove disambiguation.\n",
      "As you might already pictured, lemmatization is a much more resource-intensive task than performing a stemming process. At the same time, since it requires more knowledge about the language structure than a stemming approach, it demands more computational power than setting up or adapting a stemming algorithm.\n",
      "Topic Modeling\n",
      "Is as a method for uncovering hidden structures in sets of texts or documents. In essence it clusters texts to discover latent topics based on their contents, processing individual words and assigning them values based on their distribution. This technique is based on the assumptions that each document consists of a mixture of topics and that each topic consists of a set of words, which means that if we can spot these hidden topics we can unlock the meaning of our texts.\n",
      "From the universe of topic modelling techniques, Latent Dirichlet Allocation (LDA) is probably the most commonly used. This relatively new algorithm (invented less than 20 years ago) works as an unsupervised learning method that discovers different topics underlying a collection of documents. In unsupervised learning methods like this one, there is no output variable to guide the learning process and data is explored by algorithms to find patterns. To be more specific, LDA finds groups of related words by:\n",
      "Assigning each word to a random topic, where the user defines the number of topics it wishes to uncover. You don’t define the topics themselves (you define just the number of topics) and the algorithm will map all documents to the topics in a way that words in each document are mostly captured by those imaginary topics.\n",
      "The algorithm goes through each word iteratively and reassigns the word to a topic taking into considerations the probability that the word belongs to a topic, and the probability that the document will be generated by a topic. These probabilities are calculated multiple times, until the convergence of the algorithm.\n",
      "Unlike other clustering algorithms like  that perform hard clustering (where topics are disjointed), LDA assigns each document to a mixture of topics, which means that each document can be described by one or more topics (e.g. Document 1 is described by 70% of topic A, 20% of topic B and 10% of topic C) and reflect more realistic results.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_text = []\n",
    "\n",
    "doc = Document(\"../../../resources/day_02/NLP.docx\")\n",
    "\n",
    "for paragrah in doc.paragraphs:\n",
    "    all_text.append(paragrah.text)\n",
    "    \n",
    "print(\"\\n\".join(all_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c229cebd",
   "metadata": {},
   "source": [
    "## Read A PDF Document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac8d738",
   "metadata": {},
   "source": [
    "PyPDF2 library can work with PDF documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2f8314d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfFileReader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c248aacc",
   "metadata": {},
   "source": [
    "### Extract theText from the First Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d1292e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deepcontextualizedwordrepresentations\n",
      "MatthewE.Peters\n",
      "y\n",
      ",MarkNeumann\n",
      "y\n",
      ",MohitIyyer\n",
      "y\n",
      ",MattGardner\n",
      "y\n",
      ",\n",
      "f\n",
      "matthewp,markn,mohiti,mattg\n",
      "g\n",
      "@allenai.org\n",
      "ChristopherClark\n",
      "\n",
      ",KentonLee\n",
      "\n",
      ",LukeZettlemoyer\n",
      "\n",
      "f\n",
      "csquared,kentonl,lsz\n",
      "g\n",
      "@cs.washington.edu\n",
      "y\n",
      "AllenInstituteforIntelligence\n",
      "\n",
      "PaulG.AllenSchoolofComputerScience&Engineering,UniversityofWashington\n",
      "Abstract\n",
      "Weintroduceanewtypeof\n",
      "deepcontextual-\n",
      "ized\n",
      "wordrepresentationthatmodelsboth(1)\n",
      "complexcharacteristicsofworduse(e.g.,syn-\n",
      "taxandsemantics),and(2)howtheseuses\n",
      "varyacrosslinguisticcontexts(i.e.,tomodel\n",
      "polysemy).Ourwordvectorsarelearnedfunc-\n",
      "tionsoftheinternalstatesofadeepbidirec-\n",
      "tionallanguagemodel(biLM),whichispre-\n",
      "trainedonalargetextcorpus.Weshowthat\n",
      "theserepresentationscanbeeasilyaddedto\n",
      "existingmodelsandimprovethe\n",
      "stateoftheartacrosssixchallengingNLP\n",
      "problems,includingquestionanswering,tex-\n",
      "tualentailmentandsentimentanalysis.We\n",
      "alsopresentananalysisshowingthatexposing\n",
      "thedeepinternalsofthepre-trainednetworkis\n",
      "crucial,allowingdownstreammodelstomix\n",
      "differenttypesofsemi-supervisionsignals.\n",
      "1Introduction\n",
      "Pre-trainedwordrepresentations(\n",
      "Mikolovetal.\n",
      ",\n",
      "2013\n",
      ";\n",
      "Penningtonetal.\n",
      ",\n",
      "2014\n",
      ")areakeycompo-\n",
      "nentinmanyneurallanguageunderstandingmod-\n",
      "els.However,learninghighqualityrepresenta-\n",
      "tionscanbechallenging.Theyshouldideally\n",
      "modelboth(1)complexcharacteristicsofword\n",
      "use(e.g.,syntaxandsemantics),and(2)howthese\n",
      "usesvaryacrosslinguisticcontexts(i.e.,tomodel\n",
      "polysemy).Inthispaper,weintroduceanewtype\n",
      "of\n",
      "deepcontextualized\n",
      "wordrepresentationthat\n",
      "directlyaddressesbothchallenges,canbeeasily\n",
      "integratedintoexistingmodels,and\n",
      "improvesthestateoftheartineveryconsidered\n",
      "caseacrossarangeofchallenginglanguageun-\n",
      "derstandingproblems.\n",
      "Ourrepresentationsdifferfromtraditionalword\n",
      "typeembeddingsinthateachtokenisassigneda\n",
      "representationthatisafunctionoftheentireinput\n",
      "sentence.Weusevectorsderivedfromabidirec-\n",
      "tionalLSTMthatistrainedwithacoupledlan-\n",
      "guagemodel(LM)objectiveonalargetextcor-\n",
      "pus.Forthisreason,wecallthemELMo(Em-\n",
      "beddingsfromLanguageModels)representations.\n",
      "Unlikepreviousapproachesforlearningcontextu-\n",
      "alizedwordvectors(\n",
      "Petersetal.\n",
      ",\n",
      "2017\n",
      ";\n",
      "McCann\n",
      "etal.\n",
      ",\n",
      "2017\n",
      "),ELMorepresentationsaredeep,in\n",
      "thesensethattheyareafunctionofallofthein-\n",
      "ternallayersofthebiLM.More,we\n",
      "learnalinearcombinationofthevectorsstacked\n",
      "aboveeachinputwordforeachendtask,which\n",
      "markedlyimprovesperformanceoverjustusing\n",
      "thetopLSTMlayer.\n",
      "Combiningtheinternalstatesinthismanneral-\n",
      "lowsforveryrichwordrepresentations.Usingin-\n",
      "trinsicevaluations,weshowthatthehigher-level\n",
      "LSTMstatescapturecontext-dependentaspects\n",
      "ofwordmeaning(e.g.,theycanbeusedwith-\n",
      "outtoperformwellonsupervised\n",
      "wordsensedisambiguationtasks)whilelower-\n",
      "levelstatesmodelaspectsofsyntax(e.g.,theycan\n",
      "beusedtodopart-of-speechtagging).Simultane-\n",
      "ouslyexposingallofthesesignalsishighlybene-\n",
      "allowingthelearnedmodelsselectthetypes\n",
      "ofsemi-supervisionthataremostusefulforeach\n",
      "endtask.\n",
      "ExtensiveexperimentsdemonstratethatELMo\n",
      "representationsworkextremelywellinpractice.\n",
      "Weshowthattheycanbeeasilyaddedto\n",
      "existingmodelsforsixdiverseandchallenging\n",
      "languageunderstandingproblems,includingtex-\n",
      "tualentailment,questionansweringandsentiment\n",
      "analysis.TheadditionofELMorepresentations\n",
      "aloneimprovesthestateoftheart\n",
      "ineverycase,includingupto20%relativeerror\n",
      "reductions.Fortaskswheredirectcomparisons\n",
      "arepossible,ELMooutperformsCoVe(\n",
      "McCann\n",
      "etal.\n",
      ",\n",
      "2017\n",
      "),whichcomputescontextualizedrep-\n",
      "resentationsusinganeuralmachinetranslationen-\n",
      "coder.Finally,ananalysisofbothELMoand\n",
      "CoVerevealsthatdeeprepresentationsoutperform\n",
      "arXiv:1802.05365v2  [cs.CL]  22 Mar 2018\n"
     ]
    }
   ],
   "source": [
    "reader = PdfFileReader(open(\"../../../resources/day_02/ELMo.pdf\", 'rb'))\n",
    "\n",
    "print(reader.getPage(0).extractText()) #0 is first page"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49883695",
   "metadata": {},
   "source": [
    "## Read Text From A Csv File"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91971e0a",
   "metadata": {},
   "source": [
    "Pandas is a great library to use if you want to read text from a csv file. pandas.read_csv() can read a comma-separated values (csv) file into DataFrame. We can also optionally iterate or break the file into chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c27b0cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv(\"../../../resources/day_02/financial.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eff6ec3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Series_reference</th>\n",
       "      <th>Period</th>\n",
       "      <th>Data_value</th>\n",
       "      <th>Suppressed</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>UNITS</th>\n",
       "      <th>Magnitude</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Group</th>\n",
       "      <th>Series_title_1</th>\n",
       "      <th>Series_title_2</th>\n",
       "      <th>Series_title_3</th>\n",
       "      <th>Series_title_4</th>\n",
       "      <th>Series_title_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BDCQ.SF1AA2CA</td>\n",
       "      <td>2016.06</td>\n",
       "      <td>1116.386</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>Dollars</td>\n",
       "      <td>6</td>\n",
       "      <td>Business Data Collection - BDC</td>\n",
       "      <td>Industry by financial variable</td>\n",
       "      <td>Sales (operating income)</td>\n",
       "      <td>Forestry and Logging</td>\n",
       "      <td>Current prices</td>\n",
       "      <td>Unadjusted</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BDCQ.SF1AA2CA</td>\n",
       "      <td>2016.09</td>\n",
       "      <td>1070.874</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>Dollars</td>\n",
       "      <td>6</td>\n",
       "      <td>Business Data Collection - BDC</td>\n",
       "      <td>Industry by financial variable</td>\n",
       "      <td>Sales (operating income)</td>\n",
       "      <td>Forestry and Logging</td>\n",
       "      <td>Current prices</td>\n",
       "      <td>Unadjusted</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BDCQ.SF1AA2CA</td>\n",
       "      <td>2016.12</td>\n",
       "      <td>1054.408</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>Dollars</td>\n",
       "      <td>6</td>\n",
       "      <td>Business Data Collection - BDC</td>\n",
       "      <td>Industry by financial variable</td>\n",
       "      <td>Sales (operating income)</td>\n",
       "      <td>Forestry and Logging</td>\n",
       "      <td>Current prices</td>\n",
       "      <td>Unadjusted</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BDCQ.SF1AA2CA</td>\n",
       "      <td>2017.03</td>\n",
       "      <td>1010.665</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>Dollars</td>\n",
       "      <td>6</td>\n",
       "      <td>Business Data Collection - BDC</td>\n",
       "      <td>Industry by financial variable</td>\n",
       "      <td>Sales (operating income)</td>\n",
       "      <td>Forestry and Logging</td>\n",
       "      <td>Current prices</td>\n",
       "      <td>Unadjusted</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BDCQ.SF1AA2CA</td>\n",
       "      <td>2017.06</td>\n",
       "      <td>1233.700</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>Dollars</td>\n",
       "      <td>6</td>\n",
       "      <td>Business Data Collection - BDC</td>\n",
       "      <td>Industry by financial variable</td>\n",
       "      <td>Sales (operating income)</td>\n",
       "      <td>Forestry and Logging</td>\n",
       "      <td>Current prices</td>\n",
       "      <td>Unadjusted</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3055</th>\n",
       "      <td>BDCQ.SF8RS2CA</td>\n",
       "      <td>2020.03</td>\n",
       "      <td>141.986</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>Dollars</td>\n",
       "      <td>6</td>\n",
       "      <td>Business Data Collection - BDC</td>\n",
       "      <td>Industry by financial variable</td>\n",
       "      <td>Operating profit</td>\n",
       "      <td>Other Services</td>\n",
       "      <td>Current prices</td>\n",
       "      <td>Unadjusted</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3056</th>\n",
       "      <td>BDCQ.SF8RS2CA</td>\n",
       "      <td>2020.06</td>\n",
       "      <td>-5.260</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>Dollars</td>\n",
       "      <td>6</td>\n",
       "      <td>Business Data Collection - BDC</td>\n",
       "      <td>Industry by financial variable</td>\n",
       "      <td>Operating profit</td>\n",
       "      <td>Other Services</td>\n",
       "      <td>Current prices</td>\n",
       "      <td>Unadjusted</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3057</th>\n",
       "      <td>BDCQ.SF8RS2CA</td>\n",
       "      <td>2020.09</td>\n",
       "      <td>73.572</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>Dollars</td>\n",
       "      <td>6</td>\n",
       "      <td>Business Data Collection - BDC</td>\n",
       "      <td>Industry by financial variable</td>\n",
       "      <td>Operating profit</td>\n",
       "      <td>Other Services</td>\n",
       "      <td>Current prices</td>\n",
       "      <td>Unadjusted</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3058</th>\n",
       "      <td>BDCQ.SF8RS2CA</td>\n",
       "      <td>2020.12</td>\n",
       "      <td>229.689</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>Dollars</td>\n",
       "      <td>6</td>\n",
       "      <td>Business Data Collection - BDC</td>\n",
       "      <td>Industry by financial variable</td>\n",
       "      <td>Operating profit</td>\n",
       "      <td>Other Services</td>\n",
       "      <td>Current prices</td>\n",
       "      <td>Unadjusted</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3059</th>\n",
       "      <td>BDCQ.SF8RS2CA</td>\n",
       "      <td>2021.03</td>\n",
       "      <td>155.167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>Dollars</td>\n",
       "      <td>6</td>\n",
       "      <td>Business Data Collection - BDC</td>\n",
       "      <td>Industry by financial variable</td>\n",
       "      <td>Operating profit</td>\n",
       "      <td>Other Services</td>\n",
       "      <td>Current prices</td>\n",
       "      <td>Unadjusted</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3060 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Series_reference   Period  Data_value Suppressed STATUS    UNITS  \\\n",
       "0       BDCQ.SF1AA2CA  2016.06    1116.386        NaN      F  Dollars   \n",
       "1       BDCQ.SF1AA2CA  2016.09    1070.874        NaN      F  Dollars   \n",
       "2       BDCQ.SF1AA2CA  2016.12    1054.408        NaN      F  Dollars   \n",
       "3       BDCQ.SF1AA2CA  2017.03    1010.665        NaN      F  Dollars   \n",
       "4       BDCQ.SF1AA2CA  2017.06    1233.700        NaN      F  Dollars   \n",
       "...               ...      ...         ...        ...    ...      ...   \n",
       "3055    BDCQ.SF8RS2CA  2020.03     141.986        NaN      F  Dollars   \n",
       "3056    BDCQ.SF8RS2CA  2020.06      -5.260        NaN      F  Dollars   \n",
       "3057    BDCQ.SF8RS2CA  2020.09      73.572        NaN      F  Dollars   \n",
       "3058    BDCQ.SF8RS2CA  2020.12     229.689        NaN      F  Dollars   \n",
       "3059    BDCQ.SF8RS2CA  2021.03     155.167        NaN      F  Dollars   \n",
       "\n",
       "      Magnitude                         Subject  \\\n",
       "0             6  Business Data Collection - BDC   \n",
       "1             6  Business Data Collection - BDC   \n",
       "2             6  Business Data Collection - BDC   \n",
       "3             6  Business Data Collection - BDC   \n",
       "4             6  Business Data Collection - BDC   \n",
       "...         ...                             ...   \n",
       "3055          6  Business Data Collection - BDC   \n",
       "3056          6  Business Data Collection - BDC   \n",
       "3057          6  Business Data Collection - BDC   \n",
       "3058          6  Business Data Collection - BDC   \n",
       "3059          6  Business Data Collection - BDC   \n",
       "\n",
       "                               Group            Series_title_1  \\\n",
       "0     Industry by financial variable  Sales (operating income)   \n",
       "1     Industry by financial variable  Sales (operating income)   \n",
       "2     Industry by financial variable  Sales (operating income)   \n",
       "3     Industry by financial variable  Sales (operating income)   \n",
       "4     Industry by financial variable  Sales (operating income)   \n",
       "...                              ...                       ...   \n",
       "3055  Industry by financial variable          Operating profit   \n",
       "3056  Industry by financial variable          Operating profit   \n",
       "3057  Industry by financial variable          Operating profit   \n",
       "3058  Industry by financial variable          Operating profit   \n",
       "3059  Industry by financial variable          Operating profit   \n",
       "\n",
       "            Series_title_2  Series_title_3 Series_title_4  Series_title_5  \n",
       "0     Forestry and Logging  Current prices     Unadjusted             NaN  \n",
       "1     Forestry and Logging  Current prices     Unadjusted             NaN  \n",
       "2     Forestry and Logging  Current prices     Unadjusted             NaN  \n",
       "3     Forestry and Logging  Current prices     Unadjusted             NaN  \n",
       "4     Forestry and Logging  Current prices     Unadjusted             NaN  \n",
       "...                    ...             ...            ...             ...  \n",
       "3055        Other Services  Current prices     Unadjusted             NaN  \n",
       "3056        Other Services  Current prices     Unadjusted             NaN  \n",
       "3057        Other Services  Current prices     Unadjusted             NaN  \n",
       "3058        Other Services  Current prices     Unadjusted             NaN  \n",
       "3059        Other Services  Current prices     Unadjusted             NaN  \n",
       "\n",
       "[3060 rows x 14 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05da9708",
   "metadata": {},
   "source": [
    "## Read Text From An Excel Spreadsheet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e791a529",
   "metadata": {},
   "source": [
    "Pandas can be used to read text from an excel spreadsheet. The key is to import the Excel sheets as dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b50ca01",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_excel(\"../../../resources/day_02/person.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "215f6799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>First Name</th>\n",
       "      <th>Last Name</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Country</th>\n",
       "      <th>Age</th>\n",
       "      <th>Date</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Dulce</td>\n",
       "      <td>Abril</td>\n",
       "      <td>Female</td>\n",
       "      <td>United States</td>\n",
       "      <td>32</td>\n",
       "      <td>15/10/2017</td>\n",
       "      <td>1562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Mara</td>\n",
       "      <td>Hashimoto</td>\n",
       "      <td>Female</td>\n",
       "      <td>Great Britain</td>\n",
       "      <td>25</td>\n",
       "      <td>16/08/2016</td>\n",
       "      <td>1582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Philip</td>\n",
       "      <td>Gent</td>\n",
       "      <td>Male</td>\n",
       "      <td>France</td>\n",
       "      <td>36</td>\n",
       "      <td>21/05/2015</td>\n",
       "      <td>2587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Kathleen</td>\n",
       "      <td>Hanner</td>\n",
       "      <td>Female</td>\n",
       "      <td>United States</td>\n",
       "      <td>25</td>\n",
       "      <td>15/10/2017</td>\n",
       "      <td>3549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Nereida</td>\n",
       "      <td>Magwood</td>\n",
       "      <td>Female</td>\n",
       "      <td>United States</td>\n",
       "      <td>58</td>\n",
       "      <td>16/08/2016</td>\n",
       "      <td>2468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Gaston</td>\n",
       "      <td>Brumm</td>\n",
       "      <td>Male</td>\n",
       "      <td>United States</td>\n",
       "      <td>24</td>\n",
       "      <td>21/05/2015</td>\n",
       "      <td>2554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Etta</td>\n",
       "      <td>Hurn</td>\n",
       "      <td>Female</td>\n",
       "      <td>Great Britain</td>\n",
       "      <td>56</td>\n",
       "      <td>15/10/2017</td>\n",
       "      <td>3598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Earlean</td>\n",
       "      <td>Melgar</td>\n",
       "      <td>Female</td>\n",
       "      <td>United States</td>\n",
       "      <td>27</td>\n",
       "      <td>16/08/2016</td>\n",
       "      <td>2456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Vincenza</td>\n",
       "      <td>Weiland</td>\n",
       "      <td>Female</td>\n",
       "      <td>United States</td>\n",
       "      <td>40</td>\n",
       "      <td>21/05/2015</td>\n",
       "      <td>6548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0 First Name  Last Name  Gender        Country  Age        Date    Id\n",
       "0  1      Dulce      Abril  Female  United States   32  15/10/2017  1562\n",
       "1  2       Mara  Hashimoto  Female  Great Britain   25  16/08/2016  1582\n",
       "2  3     Philip       Gent    Male         France   36  21/05/2015  2587\n",
       "3  4   Kathleen     Hanner  Female  United States   25  15/10/2017  3549\n",
       "4  5    Nereida    Magwood  Female  United States   58  16/08/2016  2468\n",
       "5  6     Gaston      Brumm    Male  United States   24  21/05/2015  2554\n",
       "6  7       Etta       Hurn  Female  Great Britain   56  15/10/2017  3598\n",
       "7  8    Earlean     Melgar  Female  United States   27  16/08/2016  2456\n",
       "8  9   Vincenza    Weiland  Female  United States   40  21/05/2015  6548"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f063de59",
   "metadata": {},
   "source": [
    "## Read Outlook Emails"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e64831",
   "metadata": {},
   "source": [
    "There are a lot of useful information that is sent via Email messages. We can use Python to read text from the emails. Win32 is a great API for that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a096ba",
   "metadata": {},
   "source": [
    "### Use the api to get the contents of an email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0bbdb722",
   "metadata": {},
   "outputs": [],
   "source": [
    "import win32com.client\n",
    "\n",
    "# my_outlook = win32com.client.Dispatch(\"Outlook.Application\").GetNamespace(\"MAPI\")\n",
    "\n",
    "# folder = outlook.GetDefaultFolder(6) #index \n",
    "# for item in folder.Items:\n",
    "#     print(item.body)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd712805",
   "metadata": {},
   "source": [
    "## Extract RSS Feeds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b5c57b",
   "metadata": {},
   "source": [
    "feedparser is a fantastic library to extract the RSS feeds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2deeae",
   "metadata": {},
   "source": [
    "### Use the feedparser to extract the keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b1d7b3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import feedparser\n",
    "\n",
    "feed = feedparser.parse(\"https://www.feedotter.com/blog/find-an-rss-feed-url/\")\n",
    "for entry in feed.entries:\n",
    "    print(entry.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "64fdc74b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bozo': 1,\n",
       " 'entries': [],\n",
       " 'feed': {'html': {'lang': 'en-US', 'prefix': 'og: https://ogp.me/ns#'},\n",
       "  'meta': {'name': 'msapplication-TileImage',\n",
       "   'content': 'https://mk0successfeedoqagp8.kinstacdn.com/wp-content/uploads/2019/08/cropped-feedotter_ICON.png'},\n",
       "  'links': [{'rel': 'canonical',\n",
       "    'href': 'https://www.feedotter.com/blog/find-an-rss-feed-url/',\n",
       "    'type': 'text/html'},\n",
       "   {'rel': 'dns-prefetch',\n",
       "    'href': 'https://js.hs-scripts.com',\n",
       "    'type': 'text/html'},\n",
       "   {'rel': 'dns-prefetch',\n",
       "    'href': 'https://assets.calendly.com',\n",
       "    'type': 'text/html'},\n",
       "   {'rel': 'dns-prefetch',\n",
       "    'href': 'https://calendly.com',\n",
       "    'type': 'text/html'},\n",
       "   {'rel': 'dns-prefetch',\n",
       "    'href': 'https://www.gstatic.com',\n",
       "    'type': 'text/html'},\n",
       "   {'rel': 'dns-prefetch',\n",
       "    'href': 'https://www.google.com',\n",
       "    'type': 'text/html'},\n",
       "   {'rel': 'dns-prefetch',\n",
       "    'href': 'https://www.googletagmanager.com',\n",
       "    'type': 'text/html'},\n",
       "   {'rel': 'dns-prefetch',\n",
       "    'href': 'https://mk0successfeedoqagp8.kinstacdn.com',\n",
       "    'type': 'text/html'},\n",
       "   {'rel': 'dns-prefetch', 'href': 'https://driftt.com', 'type': 'text/html'},\n",
       "   {'rel': 'dns-prefetch',\n",
       "    'href': 'https://customer.api.drift.com',\n",
       "    'type': 'text/html'},\n",
       "   {'rel': 'dns-prefetch',\n",
       "    'href': 'https://js.driftt.com',\n",
       "    'type': 'text/html'},\n",
       "   {'rel': 'dns-prefetch',\n",
       "    'href': 'https://connect.facebook.net',\n",
       "    'type': 'text/html'},\n",
       "   {'rel': 'dns-prefetch',\n",
       "    'href': 'https://www.googleadservices.com',\n",
       "    'type': 'text/html'},\n",
       "   {'rel': 'dns-prefetch',\n",
       "    'href': 'https://js-agent.newrelic.com',\n",
       "    'type': 'text/html'},\n",
       "   {'rel': 'dns-prefetch',\n",
       "    'href': 'https://www.google-analytics.com',\n",
       "    'type': 'text/html'},\n",
       "   {'rel': 'dns-prefetch',\n",
       "    'href': 'https://usepopups.com',\n",
       "    'type': 'text/html'},\n",
       "   {'rel': 'dns-prefetch',\n",
       "    'href': 'https://sjs.bizographics.com',\n",
       "    'type': 'text/html'},\n",
       "   {'rel': 'dns-prefetch',\n",
       "    'href': 'https://px.ads.linkedin.com',\n",
       "    'type': 'text/html'},\n",
       "   {'rel': 'dns-prefetch',\n",
       "    'href': 'https://www.linkedin.com',\n",
       "    'type': 'text/html'},\n",
       "   {'rel': 'dns-prefetch',\n",
       "    'href': 'https://fonts.gstatic.com',\n",
       "    'type': 'text/html'},\n",
       "   {'href': 'https://mk0successfeedoqagp8.kinstacdn.com',\n",
       "    'rel': 'preconnect',\n",
       "    'type': 'text/html'},\n",
       "   {'data-minify': '1',\n",
       "    'rel': 'stylesheet',\n",
       "    'id': 'oxygen-css',\n",
       "    'href': 'https://mk0successfeedoqagp8.kinstacdn.com/wp-content/cache/min/1/wp-content/plugins/oxygen/component-framework/oxygen.css?ver=1630598819',\n",
       "    'type': 'text/css',\n",
       "    'media': 'all'},\n",
       "   {'rel': 'stylesheet',\n",
       "    'id': 'ivory-search-styles-css',\n",
       "    'href': 'https://mk0successfeedoqagp8.kinstacdn.com/wp-content/plugins/add-search-to-menu/public/css/ivory-search.min.css?ver=4.6.5',\n",
       "    'type': 'text/css',\n",
       "    'media': 'all'},\n",
       "   {'rel': 'stylesheet',\n",
       "    'id': 'social_warfare-css',\n",
       "    'href': 'https://mk0successfeedoqagp8.kinstacdn.com/wp-content/plugins/social-warfare/assets/css/style.min.css?ver=4.3.0',\n",
       "    'type': 'text/css',\n",
       "    'media': 'all'},\n",
       "   {'rel': 'https://api.w.org/',\n",
       "    'href': 'https://www.feedotter.com/wp-json/',\n",
       "    'type': 'text/html'},\n",
       "   {'rel': 'alternate',\n",
       "    'type': 'application/json',\n",
       "    'href': 'https://www.feedotter.com/wp-json/wp/v2/posts/20092'},\n",
       "   {'rel': 'edituri',\n",
       "    'type': 'application/rsd+xml',\n",
       "    'title': 'RSD',\n",
       "    'href': 'https://www.feedotter.com/xmlrpc.php?rsd'},\n",
       "   {'rel': 'wlwmanifest',\n",
       "    'type': 'application/wlwmanifest+xml',\n",
       "    'href': 'https://mk0successfeedoqagp8.kinstacdn.com/wp-includes/wlwmanifest.xml'},\n",
       "   {'rel': 'shortlink',\n",
       "    'href': 'https://www.feedotter.com/?p=20092',\n",
       "    'type': 'text/html'},\n",
       "   {'rel': 'icon',\n",
       "    'href': 'https://mk0successfeedoqagp8.kinstacdn.com/wp-content/uploads/2019/08/cropped-feedotter_ICON-50x50.png',\n",
       "    'sizes': '32x32',\n",
       "    'type': 'text/html'},\n",
       "   {'rel': 'icon',\n",
       "    'href': 'https://mk0successfeedoqagp8.kinstacdn.com/wp-content/uploads/2019/08/cropped-feedotter_ICON.png',\n",
       "    'sizes': '192x192',\n",
       "    'type': 'text/html'},\n",
       "   {'rel': 'apple-touch-icon',\n",
       "    'href': 'https://mk0successfeedoqagp8.kinstacdn.com/wp-content/uploads/2019/08/cropped-feedotter_ICON.png',\n",
       "    'type': 'text/html'},\n",
       "   {'href': 'https://fonts.googleapis.com/css?family=Nunito+Sans:100,200,300,400,500,600,700,800,900|Nunito+Sans:100,200,300,400,500,600,700,800,900',\n",
       "    'rel': 'stylesheet',\n",
       "    'type': 'text/html'},\n",
       "   {'rel': 'stylesheet',\n",
       "    'id': 'oxygen-styles-css',\n",
       "    'href': 'https://www.feedotter.com/blog/find-an-rss-feed-url/?xlink=css&#038;ver=5.8',\n",
       "    'type': 'text/css',\n",
       "    'media': 'all'}],\n",
       "  'script': {'type': 'text/javascript'},\n",
       "  'style': {'id': 'rocket-lazyload-nojs-css'}},\n",
       " 'headers': {'date': 'Fri, 03 Sep 2021 08:22:58 GMT',\n",
       "  'content-type': 'text/html; charset=UTF-8',\n",
       "  'transfer-encoding': 'chunked',\n",
       "  'connection': 'close',\n",
       "  'cf-ray': '688d92c09c2c459b-SIN',\n",
       "  'content-encoding': 'gzip',\n",
       "  'link': '<https://www.feedotter.com/wp-json/>; rel=\"https://api.w.org/\", <https://www.feedotter.com/wp-json/wp/v2/posts/20092>; rel=\"alternate\"; type=\"application/json\", <https://www.feedotter.com/?p=20092>; rel=shortlink',\n",
       "  'vary': 'Accept-Encoding',\n",
       "  'cf-cache-status': 'DYNAMIC',\n",
       "  'expect-ct': 'max-age=604800, report-uri=\"https://report-uri.cloudflare.com/cdn-cgi/beacon/expect-ct\"',\n",
       "  'ki-edge': 'v=16.3',\n",
       "  'x-content-type-options': 'nosniff',\n",
       "  'x-edge-location-klb': '1',\n",
       "  'x-kinsta-cache': 'HIT',\n",
       "  'server': 'cloudflare',\n",
       "  'alt-svc': 'h3-27=\":443\"; ma=86400, h3-28=\":443\"; ma=86400, h3-29=\":443\"; ma=86400, h3=\":443\"; ma=86400'},\n",
       " 'href': 'https://www.feedotter.com/blog/find-an-rss-feed-url/',\n",
       " 'status': 200,\n",
       " 'encoding': 'UTF-8',\n",
       " 'bozo_exception': xml.sax._exceptions.SAXParseException('not well-formed (invalid token)'),\n",
       " 'version': '',\n",
       " 'namespaces': {'': 'http://www.w3.org/2000/svg',\n",
       "  'xlink': 'http://www.w3.org/1999/xlink'}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b7019e",
   "metadata": {},
   "source": [
    "# Contributors\n",
    "\n",
    "**Author**\n",
    "<br>Chee Lam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627c6b9b",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "1. [NLP: Python Data Extraction From Social Media, Emails, Documents, Webpages, RSS & Images](https://medium.com/fintechexplained/nlp-python-data-extraction-from-social-media-emails-images-documents-web-pages-58d2f148f5f4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
